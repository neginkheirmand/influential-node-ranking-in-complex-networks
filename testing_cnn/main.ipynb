{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading (JAZZ) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03535, 0.01162, 0.00677, 0.01187, 0.04662, 0.0052 , 0.05475,\n",
       "       0.02631, 0.02641, 0.03737, 0.02495, 0.02399, 0.01455, 0.02444,\n",
       "       0.01005, 0.0099 , 0.01288, 0.04475, 0.02091, 0.02848, 0.00732,\n",
       "       0.02778, 0.02278, 0.02909, 0.00657, 0.02348, 0.01152, 0.02677,\n",
       "       0.02904, 0.00525, 0.02394, 0.04505, 0.03894, 0.0099 , 0.04515,\n",
       "       0.03146, 0.00631, 0.01843, 0.01278, 0.03126, 0.0102 , 0.01803,\n",
       "       0.03848, 0.04167, 0.0096 , 0.0304 , 0.00525, 0.01667, 0.05677,\n",
       "       0.03081, 0.01955, 0.00778, 0.03909, 0.04394, 0.02556, 0.04662,\n",
       "       0.05177, 0.03338, 0.01838, 0.07551, 0.03995, 0.0502 , 0.0402 ,\n",
       "       0.0451 , 0.04258, 0.04672, 0.03722, 0.02389, 0.06515, 0.06778,\n",
       "       0.03369, 0.02015, 0.02747, 0.02444, 0.01616, 0.02298, 0.02914,\n",
       "       0.03692, 0.01591, 0.01616, 0.04485, 0.01222, 0.06045, 0.01889,\n",
       "       0.01919, 0.03177, 0.02394, 0.05086, 0.03364, 0.02318, 0.03475,\n",
       "       0.00586, 0.03702, 0.03621, 0.04763, 0.04343, 0.02141, 0.06126,\n",
       "       0.07263, 0.04646, 0.04697, 0.02227, 0.02692, 0.02485, 0.04389,\n",
       "       0.04611, 0.04222, 0.05702, 0.05076, 0.0546 , 0.04449, 0.03828,\n",
       "       0.015  , 0.05268, 0.00833, 0.01616, 0.02177, 0.0504 , 0.01323,\n",
       "       0.00566, 0.035  , 0.07313, 0.04096, 0.01444, 0.02995, 0.02076,\n",
       "       0.02919, 0.03192, 0.03293, 0.05848, 0.0699 , 0.08652, 0.01222,\n",
       "       0.01591, 0.0547 , 0.07919, 0.02687, 0.02298, 0.02763, 0.02318,\n",
       "       0.04222, 0.04126, 0.02338, 0.01939, 0.00616, 0.03747, 0.02323,\n",
       "       0.00641, 0.03717, 0.04359, 0.03374, 0.00596, 0.03631, 0.04449,\n",
       "       0.01626, 0.02318, 0.00576, 0.07884, 0.01576, 0.00798, 0.0401 ,\n",
       "       0.01707, 0.01909, 0.06126, 0.0054 , 0.01667, 0.02955, 0.06278,\n",
       "       0.02465, 0.06601, 0.05535, 0.02505, 0.01667, 0.05141, 0.02758,\n",
       "       0.01434, 0.03328, 0.05495, 0.03485, 0.00566, 0.01106, 0.03364,\n",
       "       0.04914, 0.02045, 0.01894, 0.01505, 0.02455, 0.01641, 0.01667,\n",
       "       0.02374, 0.02192, 0.06611, 0.04056, 0.05005, 0.04192, 0.04076,\n",
       "       0.06141, 0.01318])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "graph_feature_path = './data/jazz_Features.csv'\n",
    "graph_sir_path = './data/0.csv'\n",
    "graph_path = './data/jazz.edges'\n",
    "G = nx.read_edgelist(graph_path, comments=\"%\", nodetype=int)\n",
    "\n",
    "# Load CSV file\n",
    "labels_df = pd.read_csv(graph_sir_path)\n",
    "\n",
    "# Extract the SIR column as labels\n",
    "sir_labels = labels_df['SIR'].values  # Convert to NumPy array for easier handling\n",
    "sir_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Node Data On-the-Fly\n",
    "Why??\n",
    "\n",
    "With this approach, you call adjacency_mat and channel_set for each node during training or evaluation, generating the data just in time.\n",
    "\n",
    "### Benefits:\n",
    "* **Memory Efficiency**: You won’t need to store large feature matrices for all nodes, which is helpful if you’re working with a large dataset.\n",
    "* **Flexibility**: Adjustments to L or feature calculations don’t require re-generating or re-saving all matrices; the latest function logic is always applied.\n",
    "### Drawbacks:\n",
    "* **Speed**: Generating matrices on-the-fly can slow down training, especially if creating adjacency_mat and channel_set is computationally expensive.\n",
    "* **DataLoader Considerations**: You’ll need a custom PyTorch Dataset that generates data for each node when accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adjancency_mat(G, node, graph_feature_path, L= 9):\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    df = pd.read_csv(graph_feature_path)\n",
    "    # Ensure the DataFrame is indexed by 'Node' to make lookups easier\n",
    "    df.set_index('Node', inplace=True)\n",
    "    \n",
    "    # Sort neighbors by their WiD3 values\n",
    "    sorted_neighbors = sorted(neighbors, key=lambda x: df.at[x, 'WiD3'], reverse=True)\n",
    "    sorted_neighbors.insert(0, node) #insert node at position zero of the list \n",
    "\n",
    "    ad_matrix = np.zeros((L, L))\n",
    "    # Fill the adjacency matrix based on connections in G\n",
    "    for i, node_i in enumerate(sorted_neighbors[:L]):\n",
    "        for j, node_j in enumerate(sorted_neighbors[:L]):\n",
    "            if G.has_edge(node_i, node_j):  # Check if there's an edge between node_i and node_j\n",
    "                ad_matrix[i, j] = 1  # Set 1 if there is an edge\n",
    "\n",
    "    return ad_matrix\n",
    "#TODO: check whether the neighbors should be sorted with the same WiXt\n",
    "def channel_set(L, adj_matrix, G, graph_feature_path, WiXt,  node):  #wiDt= 'WiD3'\n",
    "    df = pd.read_csv(graph_feature_path)\n",
    "    # Ensure the DataFrame is indexed by 'Node' to make lookups easier\n",
    "    df.set_index('Node', inplace=True)\n",
    "\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    # Sort neighbors by their WiD3 values\n",
    "\n",
    "    # TODO: see what changes if you sort by different things, just remember the sorting for adjacency matrix and this function should be the same\n",
    "    # sorted_neighbors = sorted(neighbors, key=lambda x: df.at[x, WiXt], reverse=True)\n",
    "    sorted_neighbors = sorted(neighbors, key=lambda x: df.at[x, 'WiD3'], reverse=True)\n",
    "    sorted_neighbors.insert(0, node) #insert node at position zero of the list \n",
    "\n",
    "    deg_chanl_set = np.zeros((L , L)) \n",
    "    for l in range(L): \n",
    "        for k in range(L):\n",
    "            if l == k: \n",
    "                deg_chanl_set[l, k] = df.at[node, WiXt]  # WiXt+ alk(which is always 0)\n",
    "            elif k != 0 and l == 0 and adj_matrix[0, k]: # if adj_matrix[0, k] is 0 then this is a zero-padding and k_node doesnt exist\n",
    "                k_node = sorted_neighbors[k]\n",
    "                deg_chanl_set[0, k] = adj_matrix[0, k] * df.at[k_node, WiXt] \n",
    "            elif l != 0 and k == 0 and adj_matrix[l, 0]!=0 : \n",
    "                l_node = sorted_neighbors[l]\n",
    "                deg_chanl_set[l, 0] = adj_matrix[l, 0] * df.at[l_node, WiXt] \n",
    "            else: \n",
    "                deg_chanl_set[l, k] = adj_matrix[l, k] \n",
    "    return deg_chanl_set\n",
    "\n",
    "\n",
    "# L = 4\n",
    "# node = 5\n",
    "# ad_mat = adjancency_mat(G, node, csv_filename, L)\n",
    "# print(\"-------\")\n",
    "# print(channel_set(L, ad_mat, G, csv_filename, 'WiD3', node))\\\n",
    "# channel_set(L, ad_mat, G, csv_filename, 'WiH3', node)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NodeDataset(Dataset):\n",
    "    def __init__(self, G, nodes, graph_feature_path, labels, L):\n",
    "        self.G = G\n",
    "        self.nodes = nodes   #TODO: CHECK ITS ALIGNED\n",
    "        self.graph_feature_path = graph_feature_path\n",
    "        self.labels = labels  # SIR labels aligned with nodes #TODO: CHECK ITS ALIGNED\n",
    "        self.L = L\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nodes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        node = self.nodes[idx]  #TODO: CHECK ITS ALIGNED\n",
    "        \n",
    "        # Generate adjacency matrix and channel sets on the fly\n",
    "        adj_matrix = adjancency_mat(self.G, node, self.graph_feature_path, L=self.L)\n",
    "\n",
    "        degree_channel = np.zeros((3, self.L, self.L))  # 3 layers for WiD1, WiD2, WiD3\n",
    "        degree_channel[0] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiD1', node)\n",
    "        degree_channel[1] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiD2', node)\n",
    "        degree_channel[2] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiD3', node)\n",
    "\n",
    "        # Similarly for H-index channels\n",
    "        h_index_channel = np.zeros((3, self.L, self.L))  # 3 layers for WiH1, WiH2, WiH3\n",
    "        h_index_channel[0] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiH1', node)\n",
    "        h_index_channel[1] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiH2', node)\n",
    "        h_index_channel[2] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiH3', node) \n",
    "              \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert to tensors if using PyTorch\n",
    "        degree_channel = torch.tensor(degree_channel, dtype=torch.float32) \n",
    "        h_index_channel = torch.tensor(h_index_channel, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return degree_channel, h_index_channel, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Size=⌊ (Input Size+2×Padding−Kernel Size)  /  Stride   ⌋+1\n",
    "MaxPool2d Layer: Halves the spatial size.\n",
    "\n",
    "\n",
    "1. nn.Conv2d(3, 16, kernel_size=2, stride=1, padding=1)\n",
    "\n",
    "(9+2*1+2/1)+1 = 10\n",
    "(3, 9, 9) -> (16, 10, 10)\n",
    "\n",
    "2. nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "(16, 10, 10) -> (16, 5, 5)\n",
    "\n",
    "3. nn.Conv2d(16, 32, kernel_size=2, stride=1, padding=1),\n",
    "\n",
    "(16, 5, 5) -> (32, 6, 6)\n",
    "\n",
    "4. nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "(32, 6, 6) -> (32, 3, 3)\n",
    "\n",
    "5. Flattening: degree_out.view(degree_out.size(0), -1)\n",
    "\n",
    "\n",
    "The output from each branch will have the shape (batch_size, 32, 3, 3).\n",
    "When flattened, this becomes (batch_size, 32 * 3 * 3) = (batch_size, 288).\n",
    "Since I have two branches, the concatenated output will have a shape of (batch_size, 288 * 2) = (batch_size, 576)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfluenceCNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(InfluenceCNN, self).__init__()\n",
    "        \n",
    "        # Degree-based channel set convolutional branch\n",
    "        self.degree_conv = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 16, kernel_size=2, stride=1, padding=1),  # (3, 9, 9) -> (16, 10, 10)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # H-index-based channel set convolutional branch\n",
    "        self.h_index_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling (2,2)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers after concatenation\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(576, 128),  # Adjusted flattened size after pooling layers\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)  # Single output for regression\n",
    "        )\n",
    "\n",
    "    def forward(self, degree_input, h_index_input):\n",
    "        # Pass through each convolutional branch\n",
    "        degree_out = self.degree_conv(degree_input)\n",
    "        print(f\"Shape after degree_conv: {degree_out.shape}\")\n",
    "\n",
    "        h_index_out = self.h_index_conv(h_index_input)\n",
    "        print(f\"Shape after h_index_conv: {h_index_out.shape}\")\n",
    "\n",
    "\n",
    "        # Flatten and concatenate\n",
    "        degree_out = degree_out.view(degree_out.size(0), -1)\n",
    "        h_index_out = h_index_out.view(h_index_out.size(0), -1)\n",
    "        print(f\"Shape after flattening degree_out: {degree_out.shape}\")  # Debugging shape\n",
    "        print(f\"Shape after flattening h_index_out: {h_index_out.shape}\")  # Debugging shape\n",
    "\n",
    "        combined = torch.cat((degree_out, h_index_out), dim=1)\n",
    "        print(f\"Shape after concatenation: {combined.shape}\")  # Debugging shape\n",
    "\n",
    "        # Fully connected layers for prediction\n",
    "        output = self.fc(combined)\n",
    "        print(f\"Shape of output: {output.shape}\") \n",
    "        \n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 0.0052)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have all the nodes and labels loaded properly\n",
    "nodes = labels_df['Node'].values\n",
    "sir_labels = labels_df['SIR'].values\n",
    "\n",
    "# Split into training and validation sets (80% train, 20% validation)\n",
    "train_nodes, val_nodes, train_labels, val_labels = train_test_split(nodes, sir_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NodeDataset(G, train_nodes, graph_feature_path, train_labels, L=9)\n",
    "val_dataset = NodeDataset(G, val_nodes, graph_feature_path, val_labels, L=9)\n",
    "\n",
    "\n",
    "train_nodes[1],train_labels[1]   #just checking that its correctly split and gives the correct node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders:\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model, Loss Function, and Optimizer:\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = InfluenceCNN(input_size=9)  # Adjust input_size according to your data\n",
    "model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()  # For regression\n",
    "learning_rate = 0.0005\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InfluenceCNN(\n",
       "  (degree_conv): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (h_index_conv): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([30, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([30, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([30, 288])\n",
      "Shape after flattening h_index_out: torch.Size([30, 288])\n",
      "Shape after concatenation: torch.Size([30, 576])\n",
      "Shape of output: torch.Size([30, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([8, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([8, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([8, 288])\n",
      "Shape after flattening h_index_out: torch.Size([8, 288])\n",
      "Shape after concatenation: torch.Size([8, 576])\n",
      "Shape of output: torch.Size([8, 1])\n",
      "Epoch [1/20], Training Loss: 2233545.0348, Validation Loss: 2386467.0000\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([30, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([30, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([30, 288])\n",
      "Shape after flattening h_index_out: torch.Size([30, 288])\n",
      "Shape after concatenation: torch.Size([30, 576])\n",
      "Shape of output: torch.Size([30, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([8, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([8, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([8, 288])\n",
      "Shape after flattening h_index_out: torch.Size([8, 288])\n",
      "Shape after concatenation: torch.Size([8, 576])\n",
      "Shape of output: torch.Size([8, 1])\n",
      "Epoch [2/20], Training Loss: 881833.4407, Validation Loss: 1094813.9000\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([30, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([30, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([30, 288])\n",
      "Shape after flattening h_index_out: torch.Size([30, 288])\n",
      "Shape after concatenation: torch.Size([30, 576])\n",
      "Shape of output: torch.Size([30, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([8, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([8, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([8, 288])\n",
      "Shape after flattening h_index_out: torch.Size([8, 288])\n",
      "Shape after concatenation: torch.Size([8, 576])\n",
      "Shape of output: torch.Size([8, 1])\n",
      "Epoch [3/20], Training Loss: 501704.2843, Validation Loss: 361977.8563\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n",
      "Shape of output: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# Set number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ### Training Phase ###\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for degree_batch, h_index_batch, label_batch in train_loader:\n",
    "        # Move data to GPU if available\n",
    "        degree_batch = degree_batch.to(device)  # device should be set to 'cuda' or 'cpu'\n",
    "        h_index_batch = h_index_batch.to(device)\n",
    "        label_batch = label_batch.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(degree_batch, h_index_batch)\n",
    "        loss = criterion(output.squeeze(), label_batch)  # Squeeze to match dimensions\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate training loss\n",
    "        train_loss += loss.item() * degree_batch.size(0)  # Multiply by batch size\n",
    "    \n",
    "    # Calculate average training loss\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    ### Validation Phase ###\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():  # No need to compute gradients for validation\n",
    "        for degree_batch, h_index_batch, label_batch in val_loader:\n",
    "            degree_batch = degree_batch.to(device)\n",
    "            h_index_batch = h_index_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(degree_batch, h_index_batch)\n",
    "            loss = criterion(output.squeeze(), label_batch)\n",
    "            \n",
    "            # Accumulate validation loss\n",
    "            val_loss += loss.item() * degree_batch.size(0)\n",
    "    \n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    # Print loss for this epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Validation Loop:\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Tracking validation loss\n",
    "val_loss = 0.0\n",
    "\n",
    "with torch.no_grad():  # No gradient calculation during validation\n",
    "    for degree_input, h_index_input, label in val_loader:\n",
    "        degree_input, h_index_input, label = degree_input.to(device), h_index_input.to(device), label.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(degree_input, h_index_input)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output.squeeze(), label)  # squeeze to match dimensions\n",
    "        val_loss += loss.item()\n",
    "\n",
    "print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Save the Model (optional):\n",
    "torch.save(model.state_dict(), 'influence_cnn_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the model later\n",
    "model = InfluenceCNN(input_size=9)\n",
    "model.load_state_dict(torch.load('influence_cnn_model.pth'))\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
