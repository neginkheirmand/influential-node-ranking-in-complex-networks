{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading (JAZZ) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03535, 0.01162, 0.00677, 0.01187, 0.04662, 0.0052 , 0.05475,\n",
       "       0.02631, 0.02641, 0.03737, 0.02495, 0.02399, 0.01455, 0.02444,\n",
       "       0.01005, 0.0099 , 0.01288, 0.04475, 0.02091, 0.02848, 0.00732,\n",
       "       0.02778, 0.02278, 0.02909, 0.00657, 0.02348, 0.01152, 0.02677,\n",
       "       0.02904, 0.00525, 0.02394, 0.04505, 0.03894, 0.0099 , 0.04515,\n",
       "       0.03146, 0.00631, 0.01843, 0.01278, 0.03126, 0.0102 , 0.01803,\n",
       "       0.03848, 0.04167, 0.0096 , 0.0304 , 0.00525, 0.01667, 0.05677,\n",
       "       0.03081, 0.01955, 0.00778, 0.03909, 0.04394, 0.02556, 0.04662,\n",
       "       0.05177, 0.03338, 0.01838, 0.07551, 0.03995, 0.0502 , 0.0402 ,\n",
       "       0.0451 , 0.04258, 0.04672, 0.03722, 0.02389, 0.06515, 0.06778,\n",
       "       0.03369, 0.02015, 0.02747, 0.02444, 0.01616, 0.02298, 0.02914,\n",
       "       0.03692, 0.01591, 0.01616, 0.04485, 0.01222, 0.06045, 0.01889,\n",
       "       0.01919, 0.03177, 0.02394, 0.05086, 0.03364, 0.02318, 0.03475,\n",
       "       0.00586, 0.03702, 0.03621, 0.04763, 0.04343, 0.02141, 0.06126,\n",
       "       0.07263, 0.04646, 0.04697, 0.02227, 0.02692, 0.02485, 0.04389,\n",
       "       0.04611, 0.04222, 0.05702, 0.05076, 0.0546 , 0.04449, 0.03828,\n",
       "       0.015  , 0.05268, 0.00833, 0.01616, 0.02177, 0.0504 , 0.01323,\n",
       "       0.00566, 0.035  , 0.07313, 0.04096, 0.01444, 0.02995, 0.02076,\n",
       "       0.02919, 0.03192, 0.03293, 0.05848, 0.0699 , 0.08652, 0.01222,\n",
       "       0.01591, 0.0547 , 0.07919, 0.02687, 0.02298, 0.02763, 0.02318,\n",
       "       0.04222, 0.04126, 0.02338, 0.01939, 0.00616, 0.03747, 0.02323,\n",
       "       0.00641, 0.03717, 0.04359, 0.03374, 0.00596, 0.03631, 0.04449,\n",
       "       0.01626, 0.02318, 0.00576, 0.07884, 0.01576, 0.00798, 0.0401 ,\n",
       "       0.01707, 0.01909, 0.06126, 0.0054 , 0.01667, 0.02955, 0.06278,\n",
       "       0.02465, 0.06601, 0.05535, 0.02505, 0.01667, 0.05141, 0.02758,\n",
       "       0.01434, 0.03328, 0.05495, 0.03485, 0.00566, 0.01106, 0.03364,\n",
       "       0.04914, 0.02045, 0.01894, 0.01505, 0.02455, 0.01641, 0.01667,\n",
       "       0.02374, 0.02192, 0.06611, 0.04056, 0.05005, 0.04192, 0.04076,\n",
       "       0.06141, 0.01318])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "graph_feature_path = './data/jazz_Features.csv'\n",
    "graph_sir_path = './data/0.csv'\n",
    "graph_path = './data/jazz.edges'\n",
    "G = nx.read_edgelist(graph_path, comments=\"%\", nodetype=int)\n",
    "\n",
    "# Load CSV file\n",
    "labels_df = pd.read_csv(graph_sir_path)\n",
    "\n",
    "# Extract the SIR column as labels\n",
    "sir_labels = labels_df['SIR'].values  # Convert to NumPy array for easier handling\n",
    "sir_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Node Data On-the-Fly\n",
    "Why??\n",
    "\n",
    "With this approach, you call adjacency_mat and channel_set for each node during training or evaluation, generating the data just in time.\n",
    "\n",
    "### Benefits:\n",
    "* **Memory Efficiency**: You won’t need to store large feature matrices for all nodes, which is helpful if you’re working with a large dataset.\n",
    "* **Flexibility**: Adjustments to L or feature calculations don’t require re-generating or re-saving all matrices; the latest function logic is always applied.\n",
    "### Drawbacks:\n",
    "* **Speed**: Generating matrices on-the-fly can slow down training, especially if creating adjacency_mat and channel_set is computationally expensive.\n",
    "* **DataLoader Considerations**: You’ll need a custom PyTorch Dataset that generates data for each node when accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adjancency_mat(G, node, graph_feature_path, L= 9):\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    df = pd.read_csv(graph_feature_path)\n",
    "    # Ensure the DataFrame is indexed by 'Node' to make lookups easier\n",
    "    df.set_index('Node', inplace=True)\n",
    "    \n",
    "    # Sort neighbors by their WiD3 values\n",
    "    sorted_neighbors = sorted(neighbors, key=lambda x: df.at[x, 'WiD3'], reverse=True)\n",
    "    sorted_neighbors.insert(0, node) #insert node at position zero of the list \n",
    "\n",
    "    print(sorted_neighbors)\n",
    "    ad_matrix = np.zeros((L, L))\n",
    "    # Fill the adjacency matrix based on connections in G\n",
    "    for i, node_i in enumerate(sorted_neighbors[:L]):\n",
    "        for j, node_j in enumerate(sorted_neighbors[:L]):\n",
    "            if G.has_edge(node_i, node_j):  # Check if there's an edge between node_i and node_j\n",
    "                ad_matrix[i, j] = 1  # Set 1 if there is an edge\n",
    "\n",
    "    return ad_matrix\n",
    "#TODO: check whether the neighbors should be sorted with the same WiXt\n",
    "def channel_set(L, adj_matrix, G, graph_feature_path, WiXt,  node):  #wiDt= 'WiD3'\n",
    "    df = pd.read_csv(graph_feature_path)\n",
    "    # Ensure the DataFrame is indexed by 'Node' to make lookups easier\n",
    "    df.set_index('Node', inplace=True)\n",
    "\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    # Sort neighbors by their WiD3 values\n",
    "\n",
    "    # TODO: see what changes if you sort by different things, just remember the sorting for adjacency matrix and this function should be the same\n",
    "    # sorted_neighbors = sorted(neighbors, key=lambda x: df.at[x, WiXt], reverse=True)\n",
    "    sorted_neighbors = sorted(neighbors, key=lambda x: df.at[x, 'WiD3'], reverse=True)\n",
    "    sorted_neighbors.insert(0, node) #insert node at position zero of the list \n",
    "\n",
    "    deg_chanl_set = np.zeros((L , L)) \n",
    "    for l in range(L): \n",
    "        for k in range(L):\n",
    "            if l == k: \n",
    "                deg_chanl_set[l, k] = df.at[node, WiXt]  # WiXt+ alk(which is always 0)\n",
    "            elif k != 0 and l == 0 and adj_matrix[0, k]: # if adj_matrix[0, k] is 0 then this is a zero-padding and k_node doesnt exist\n",
    "                k_node = sorted_neighbors[k]\n",
    "                deg_chanl_set[0, k] = adj_matrix[0, k] * df.at[k_node, WiXt] \n",
    "            elif l != 0 and k == 0 and adj_matrix[l, 0]!=0 : \n",
    "                l_node = sorted_neighbors[l]\n",
    "                deg_chanl_set[l, 0] = adj_matrix[l, 0] * df.at[l_node, WiXt] \n",
    "            else: \n",
    "                deg_chanl_set[l, k] = adj_matrix[l, k] \n",
    "    return deg_chanl_set\n",
    "\n",
    "\n",
    "# L = 4\n",
    "# node = 5\n",
    "# ad_mat = adjancency_mat(G, node, csv_filename, L)\n",
    "# print(\"-------\")\n",
    "# print(channel_set(L, ad_mat, G, csv_filename, 'WiD3', node))\\\n",
    "# channel_set(L, ad_mat, G, csv_filename, 'WiH3', node)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NodeDataset(Dataset):\n",
    "    def __init__(self, G, nodes, graph_feature_path, labels, L):\n",
    "        self.G = G\n",
    "        self.nodes = nodes   #TODO: CHECK ITS ALIGNED\n",
    "        self.graph_feature_path = graph_feature_path\n",
    "        self.labels = labels  # SIR labels aligned with nodes #TODO: CHECK ITS ALIGNED\n",
    "        self.L = L\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nodes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        node = self.nodes[idx]  #TODO: CHECK ITS ALIGNED\n",
    "        \n",
    "        # Generate adjacency matrix and channel sets on the fly\n",
    "        adj_matrix = adjancency_mat(self.G, node, self.graph_feature_path, L=self.L)\n",
    "\n",
    "        degree_channel = np.zeros((3, self.L, self.L))  # 3 layers for WiD1, WiD2, WiD3\n",
    "        degree_channel[0] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiD1', node)\n",
    "        degree_channel[1] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiD2', node)\n",
    "        degree_channel[2] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiD3', node)\n",
    "\n",
    "        # Similarly for H-index channels\n",
    "        h_index_channel = np.zeros((3, self.L, self.L))  # 3 layers for WiH1, WiH2, WiH3\n",
    "        h_index_channel[0] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiH1', node)\n",
    "        h_index_channel[1] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiH2', node)\n",
    "        h_index_channel[2] = channel_set(self.L, adj_matrix, self.G, self.graph_feature_path, 'WiH3', node) \n",
    "              \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert to tensors if using PyTorch\n",
    "        degree_channel = torch.tensor(degree_channel, dtype=torch.float32) \n",
    "        h_index_channel = torch.tensor(h_index_channel, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return degree_channel, h_index_channel, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfluenceCNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(InfluenceCNN, self).__init__()\n",
    "        \n",
    "        # Degree-based channel set convolutional branch\n",
    "        self.degree_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=2, stride=1, padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # H-index-based channel set convolutional branch\n",
    "        self.h_index_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling (2,2)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers after concatenation\n",
    "        self.fc = nn.Sequential(\n",
    "            # nn.Linear(32 * (input_size // 8) * (input_size // 8) * 2, 128),  # Adjusted flattened size after pooling layers\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)  # Single output for regression\n",
    "        )\n",
    "\n",
    "    def forward(self, degree_input, h_index_input):\n",
    "        # Pass through each convolutional branch\n",
    "        degree_out = self.degree_conv(degree_input)\n",
    "        print(f\"Shape after degree_conv: {degree_out.shape}\")\n",
    "\n",
    "        h_index_out = self.h_index_conv(h_index_input)\n",
    "        print(f\"Shape after h_index_conv: {h_index_out.shape}\")\n",
    "\n",
    "\n",
    "        # Flatten and concatenate\n",
    "        degree_out = degree_out.view(degree_out.size(0), -1)\n",
    "        h_index_out = h_index_out.view(h_index_out.size(0), -1)\n",
    "        print(f\"Shape after flattening degree_out: {degree_out.shape}\")  # Debugging shape\n",
    "        print(f\"Shape after flattening h_index_out: {h_index_out.shape}\")  # Debugging shape\n",
    "\n",
    "        combined = torch.cat((degree_out, h_index_out), dim=1)\n",
    "        print(f\"Shape after concatenation: {combined.shape}\")  # Debugging shape\n",
    "\n",
    "        # Fully connected layers for prediction\n",
    "        output = self.fc(combined)\n",
    "        print(f\"Shape of output: {output.shape}\") \n",
    "        \n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 0.0052)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have all the nodes and labels loaded properly\n",
    "nodes = labels_df['Node'].values\n",
    "sir_labels = labels_df['SIR'].values\n",
    "\n",
    "# Split into training and validation sets (80% train, 20% validation)\n",
    "train_nodes, val_nodes, train_labels, val_labels = train_test_split(nodes, sir_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NodeDataset(G, train_nodes, graph_feature_path, train_labels, L=9)\n",
    "val_dataset = NodeDataset(G, val_nodes, graph_feature_path, val_labels, L=9)\n",
    "\n",
    "\n",
    "train_nodes[1],train_labels[1]   #just checking that its correctly split and gives the correct node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders:\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model, Loss Function, and Optimizer:\n",
    "\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = InfluenceCNN(input_size=9)  # Adjust input_size according to your data\n",
    "model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()  # For regression\n",
    "learning_rate = 0.0005\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InfluenceCNN(\n",
       "  (degree_conv): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (h_index_conv): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95, 60, 136, 132, 168, 108, 99, 131, 70, 158, 122, 7, 192, 69, 100, 101, 174, 98, 110, 171, 135, 35, 154, 179, 111, 125, 142, 193, 93, 146, 190, 127, 94, 141, 8, 78, 46, 1, 89, 91, 80]\n",
      "[65, 60, 136, 132, 168, 108, 99, 131, 122, 100, 101, 170, 98, 105, 110, 135, 35, 154, 179, 123, 106, 32, 66, 109, 44, 107, 64, 33, 40, 58, 63, 62, 50, 139]\n",
      "[79, 136, 174, 49, 118, 96, 149, 142, 5, 86, 167, 128, 147, 172, 143, 51, 126, 75, 144, 76, 163]\n",
      "[72, 60, 7, 164, 150, 161, 36, 71, 103, 74]\n",
      "[174, 60, 136, 132, 108, 99, 131, 70, 194, 83, 158, 164, 192, 69, 100, 101, 170, 98, 105, 110, 171, 95, 54, 81, 178, 197, 49, 118, 121, 149, 88, 142, 43, 127, 67, 182, 36, 141, 24, 8, 73, 22, 147, 78, 89, 143, 79, 51, 126, 75, 59, 144, 76]\n",
      "[63, 60, 132, 168, 108, 99, 131, 122, 100, 101, 98, 105, 110, 135, 35, 154, 179, 123, 106, 32, 66, 109, 65, 44, 107, 64, 33, 40, 58, 62, 91, 38]\n",
      "[67, 136, 70, 194, 83, 158, 7, 164, 192, 174, 170, 135, 54, 195, 196, 81, 178, 53, 49, 150, 149, 56, 127, 36, 55, 87, 103, 84, 134, 159]\n",
      "[173, 96, 149, 5, 86, 167, 128, 147, 90, 172, 140, 77, 26, 191, 189, 28, 184, 138, 176, 169, 13, 156, 102, 163, 4]\n",
      "[41, 136, 96, 88, 86, 77, 97, 45]\n",
      "[103, 168, 108, 83, 7, 164, 171, 35, 154, 178, 114, 150, 161, 67, 24, 112, 71, 10, 78, 1, 87, 74, 104, 72]\n",
      "[32, 60, 132, 168, 108, 99, 131, 122, 100, 101, 98, 105, 110, 135, 35, 154, 179, 111, 123, 106, 66, 109, 65, 44, 107, 64, 33, 40, 58, 63, 62, 61, 31, 189, 11, 91, 9, 162, 139, 80, 38, 23]\n",
      "[22, 136, 132, 108, 99, 131, 194, 83, 164, 100, 101, 174, 170, 98, 105, 81, 178, 197, 43, 182]\n",
      "[27, 96, 149, 5, 167, 128, 147, 172, 153, 29, 51, 126, 144, 76]\n",
      "[99, 60, 136, 132, 168, 108, 131, 70, 194, 83, 122, 164, 69, 100, 101, 174, 170, 98, 105, 110, 171, 135, 95, 35, 154, 81, 178, 179, 123, 106, 197, 32, 66, 109, 65, 44, 118, 121, 107, 64, 33, 40, 58, 63, 62, 88, 43, 182, 24, 8, 73, 22, 78, 46, 1, 187, 143, 68, 166, 59, 82]\n",
      "[40, 60, 132, 168, 108, 99, 131, 122, 100, 101, 98, 105, 110, 135, 35, 154, 179, 123, 106, 32, 66, 109, 65, 44, 107, 64, 33, 58, 63, 62, 91, 116, 38, 134, 119]\n",
      "[88, 60, 136, 132, 99, 131, 70, 158, 69, 174, 110, 196, 114, 53, 183, 96, 149, 18, 56, 50, 86, 167, 73, 128, 147, 90, 172, 140, 29, 77, 191, 143, 184, 97, 52, 41, 45]\n",
      "[89, 60, 136, 132, 83, 158, 174, 171, 95, 196, 118, 121, 149, 57, 142, 127, 141, 8]\n",
      "[171, 60, 136, 132, 168, 108, 99, 131, 70, 158, 122, 7, 192, 69, 100, 101, 174, 98, 110, 135, 95, 35, 154, 111, 44, 125, 142, 193, 93, 146, 190, 127, 94, 141, 24, 8, 78, 46, 1, 103, 89, 187, 74, 68, 166, 104]\n",
      "[140, 136, 96, 149, 18, 88, 5, 86, 167, 73, 128, 147, 90, 172, 153, 29, 77, 26, 191, 189, 28, 184, 176, 173, 169, 13, 156, 85, 102, 155, 124, 198]\n",
      "[124, 96, 5, 86, 128, 90, 153, 140, 29, 77, 26, 28, 184, 138, 176, 97, 198]\n",
      "[98, 60, 136, 132, 168, 108, 99, 131, 194, 83, 122, 164, 100, 101, 174, 170, 105, 110, 171, 135, 95, 35, 154, 81, 178, 179, 123, 106, 197, 32, 66, 109, 65, 44, 107, 64, 33, 40, 58, 63, 62, 43, 182, 8, 22, 46, 1]\n",
      "[100, 60, 136, 132, 168, 108, 99, 131, 194, 83, 122, 164, 101, 174, 170, 98, 105, 110, 171, 135, 95, 35, 154, 81, 178, 179, 123, 106, 197, 32, 66, 109, 65, 44, 107, 64, 33, 40, 58, 63, 62, 43, 182, 24, 8, 22, 78, 46, 1, 59]\n",
      "[59, 136, 99, 158, 122, 100, 174, 118, 121, 43, 143, 162, 82]\n",
      "[153, 168, 122, 111, 118, 96, 121, 149, 5, 86, 167, 71, 128, 147, 90, 172, 140, 29, 26, 28, 137, 9, 116, 13, 51, 126, 144, 76, 117, 124, 163, 4, 27, 198, 39, 181, 25, 115, 3, 37, 92, 148]\n",
      "[3, 167, 172, 153, 115]\n",
      "[113, 158, 7, 164, 196, 114, 53, 49, 57, 161, 112, 71, 10, 11]\n",
      "[112, 60, 70, 158, 7, 164, 192, 69, 195, 196, 114, 53, 49, 150, 57, 130, 61, 127, 161, 141, 71, 10, 14, 151, 87, 103, 11, 74, 113]\n",
      "[24, 60, 136, 132, 168, 108, 99, 100, 174, 105, 171, 35, 154, 81, 107, 43, 182, 78, 46, 1, 103, 91, 74, 104, 80, 20, 42, 16, 15, 48]\n",
      "[110, 60, 136, 132, 168, 108, 99, 131, 70, 122, 69, 100, 101, 174, 170, 98, 105, 171, 135, 95, 35, 154, 179, 123, 106, 32, 66, 109, 65, 44, 107, 64, 33, 40, 58, 63, 62, 88, 182, 50, 8, 73, 143, 139]\n",
      "[29, 136, 96, 149, 18, 88, 5, 86, 167, 73, 128, 147, 90, 172, 153, 140, 77, 26, 191, 28, 184, 138, 176, 169, 97, 51, 126, 144, 76, 124, 27, 198]\n",
      "[170, 136, 132, 168, 108, 99, 131, 70, 194, 83, 158, 7, 164, 192, 100, 101, 174, 98, 105, 110, 54, 195, 196, 35, 154, 81, 178, 111, 197, 53, 66, 109, 65, 118, 183, 150, 64, 56, 43, 67, 182, 36, 55, 22, 129, 12, 31, 175, 84]\n",
      "[129, 60, 136, 194, 7, 170, 54, 195, 196, 197, 53, 118, 183, 57, 18, 56, 61, 36, 55, 19, 12, 31, 175, 84]\n",
      "Shape after degree_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after h_index_conv: torch.Size([32, 32, 3, 3])\n",
      "Shape after flattening degree_out: torch.Size([32, 288])\n",
      "Shape after flattening h_index_out: torch.Size([32, 288])\n",
      "Shape after concatenation: torch.Size([32, 576])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x576 and 256x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdegree_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_index_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39msqueeze(), label_batch)  \u001b[38;5;66;03m# Squeeze to match dimensions\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\venus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\venus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[130], line 52\u001b[0m, in \u001b[0;36mInfluenceCNN.forward\u001b[1;34m(self, degree_input, h_index_input)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape after concatenation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Debugging shape\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Fully connected layers for prediction\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\venus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\venus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\venus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\venus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\venus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\venus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x576 and 256x128)"
     ]
    }
   ],
   "source": [
    "# Set number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ### Training Phase ###\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for degree_batch, h_index_batch, label_batch in train_loader:\n",
    "        # Move data to GPU if available\n",
    "        degree_batch = degree_batch.to(device)  # device should be set to 'cuda' or 'cpu'\n",
    "        h_index_batch = h_index_batch.to(device)\n",
    "        label_batch = label_batch.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(degree_batch, h_index_batch)\n",
    "        loss = criterion(output.squeeze(), label_batch)  # Squeeze to match dimensions\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate training loss\n",
    "        train_loss += loss.item() * degree_batch.size(0)  # Multiply by batch size\n",
    "    \n",
    "    # Calculate average training loss\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    ### Validation Phase ###\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():  # No need to compute gradients for validation\n",
    "        for degree_batch, h_index_batch, label_batch in val_loader:\n",
    "            degree_batch = degree_batch.to(device)\n",
    "            h_index_batch = h_index_batch.to(device)\n",
    "            label_batch = label_batch.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(degree_batch, h_index_batch)\n",
    "            loss = criterion(output.squeeze(), label_batch)\n",
    "            \n",
    "            # Accumulate validation loss\n",
    "            val_loss += loss.item() * degree_batch.size(0)\n",
    "    \n",
    "    # Calculate average validation loss\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    # Print loss for this epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Validation Loop:\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Tracking validation loss\n",
    "val_loss = 0.0\n",
    "\n",
    "with torch.no_grad():  # No gradient calculation during validation\n",
    "    for degree_input, h_index_input, label in val_loader:\n",
    "        degree_input, h_index_input, label = degree_input.to(device), h_index_input.to(device), label.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(degree_input, h_index_input)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output.squeeze(), label)  # squeeze to match dimensions\n",
    "        val_loss += loss.item()\n",
    "\n",
    "print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Save the Model (optional):\n",
    "torch.save(model.state_dict(), 'influence_cnn_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the model later\n",
    "model = InfluenceCNN(input_size=9)\n",
    "model.load_state_dict(torch.load('influence_cnn_model.pth'))\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
