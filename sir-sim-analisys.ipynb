{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ba_graph_paths(dataset_dir= \"./datasets/\"):\n",
    "    graph_list = []\n",
    "    for dirpath, _, files in os.walk(dataset_dir):\n",
    "        for filename in files:\n",
    "            try:\n",
    "                if filename.startswith(\"ba_edgelist\") and filename.endswith(\".edges\"):\n",
    "                    file_path = os.path.join(dirpath, filename) \n",
    "                    graph_list.append((file_path, os.path.splitext(filename)[0]))\n",
    "            except Exception as e: \n",
    "                print(e, f'{filename}')\n",
    "    return graph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def file_exists(file_path):\n",
    "    return os.path.isfile(file_path)\n",
    "\n",
    "\n",
    "def get_graph_paths(dataset_dir= \"./datasets/\"):\n",
    "    graph_list = []\n",
    "    for dirpath, _, files in os.walk(dataset_dir):\n",
    "        for filename in files:\n",
    "            try:\n",
    "                if filename.endswith(\".edges\"):\n",
    "                    file_path = os.path.join(dirpath, filename) \n",
    "                    graph_list.append((file_path, os.path.splitext(filename)[0]))\n",
    "            except Exception as e: \n",
    "                print(e, f'{filename}')\n",
    "    return graph_list\n",
    "\n",
    "\n",
    "def get_sir_graph_paths(net_name, num_b=3,  result_path = './datasets/SIR_Results/'):\n",
    "    paths= []\n",
    "    for i in range(num_b):\n",
    "        sir_dir =os.path.join(result_path, net_name)\n",
    "        sir_dir = os.path.join(sir_dir, f'{i}.csv')\n",
    "        paths.append(sir_dir)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def get_previously_sim_values(sir_graph_path):\n",
    "    try:\n",
    "        df = pd.read_csv(sir_graph_path)\n",
    "        values = df['Node'].tolist()\n",
    "        return values\n",
    "    except OSError as e:\n",
    "        return []\n",
    "\n",
    "def getTotalNumNodes(net_name):\n",
    "    graph_list = get_graph_paths()\n",
    "    path = ''\n",
    "    for tmp in graph_list:\n",
    "        if tmp[1]==net_name:\n",
    "            path = tmp[0]\n",
    "            \n",
    "    G = nx.read_edgelist(path, comments=\"%\", nodetype=int)\n",
    "    return G.number_of_nodes()\n",
    "\n",
    "\n",
    "def getSimNumNodes(net_name):\n",
    "    sir_paths = get_sir_graph_paths(net_name)\n",
    "    temp = [  len(get_previously_sim_values(path)) for path in sir_paths ]\n",
    "    return (temp)\n",
    "\n",
    "\n",
    "def getSortValue(net_edges_path):\n",
    "    net_edges_path=net_edges_path[0]\n",
    "    G = nx.read_edgelist(net_edges_path, comments=\"%\", nodetype=int)\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "    avg_degree = 2 * num_edges / num_nodes if num_nodes > 0 else 0\n",
    "    return num_nodes+avg_degree\n",
    "\n",
    "def getSubList(graphs, index, step):\n",
    "    sublits = []\n",
    "    for i in range(index, len(graphs), step):\n",
    "        sublits.append(graphs[i])\n",
    "    return sublits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_has_duplicates(net_name):\n",
    "    sir_paths = get_sir_graph_paths(net_name)\n",
    "    duplicates = []\n",
    "    for sir_graph_path in sir_paths:\n",
    "        try:\n",
    "            # Load the CSV file\n",
    "            df = pd.read_csv(sir_graph_path)\n",
    "            # Check for duplicate Node values\n",
    "            duplicate = df[df.duplicated(subset='Node', keep=False)]['Node'].unique()\n",
    "            if len(duplicate)>0:\n",
    "                duplicates.append(duplicate)\n",
    "            else:\n",
    "                duplicates.append([])\n",
    "                \n",
    "        except OSError as e:\n",
    "            return []\n",
    "    union_result = set(duplicates[0]).union(duplicates[1], duplicates[2])\n",
    "    union_result = list(union_result)\n",
    "    return True if len (union_result)>0 else False\n",
    "\n",
    "def get_duplicates(net_name):\n",
    "    sir_paths = get_sir_graph_paths(net_name)\n",
    "    duplicates = []\n",
    "    for sir_graph_path in sir_paths:\n",
    "        try:\n",
    "            # Load the CSV file\n",
    "            df = pd.read_csv(sir_graph_path)\n",
    "            # Check for duplicate Node values\n",
    "            duplicate = df[df.duplicated(subset='Node', keep=False)]['Node'].unique()\n",
    "            if len(duplicate)>0:\n",
    "                duplicates.append(duplicate)\n",
    "            else:\n",
    "                duplicates.append([])\n",
    "                \n",
    "        except OSError as e:\n",
    "            return []\n",
    "    union_result = set(duplicates[0]).union(duplicates[1], duplicates[2])\n",
    "    union_result = list(union_result)\n",
    "    return union_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./datasets/BA\\\\ba_edgelist_1000_10.edges', 'ba_edgelist_1000_10')\n",
      "('./datasets/BA\\\\ba_edgelist_1000_20.edges', 'ba_edgelist_1000_20')\n",
      "('./datasets/BA\\\\ba_edgelist_1000_4.edges', 'ba_edgelist_1000_4')\n",
      "('./datasets/BA\\\\ba_edgelist_2000_10.edges', 'ba_edgelist_2000_10')\n",
      "('./datasets/BA\\\\ba_edgelist_2000_20.edges', 'ba_edgelist_2000_20')\n",
      "('./datasets/BA\\\\ba_edgelist_2000_4.edges', 'ba_edgelist_2000_4')\n",
      "('./datasets/BA\\\\ba_edgelist_3000_10.edges', 'ba_edgelist_3000_10')\n",
      "('./datasets/BA\\\\ba_edgelist_3000_20.edges', 'ba_edgelist_3000_20')\n",
      "('./datasets/BA\\\\ba_edgelist_3000_4.edges', 'ba_edgelist_3000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_3000_4.edges', 'ba_edgelist_exp1_3000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_4000_4.edges', 'ba_edgelist_exp1_4000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_5000_4.edges', 'ba_edgelist_exp1_5000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_6000_4.edges', 'ba_edgelist_exp1_6000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_7000_4.edges', 'ba_edgelist_exp1_7000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_8000_4.edges', 'ba_edgelist_exp1_8000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_10.edges', 'ba_edgelist_exp2_2000_10')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_20.edges', 'ba_edgelist_exp2_2000_20')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_4.edges', 'ba_edgelist_exp2_2000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_10.edges', 'ba_edgelist_exp3_4000_10')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_2.edges', 'ba_edgelist_exp3_4000_2')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_6.edges', 'ba_edgelist_exp3_4000_6')\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "temp = get_ba_graph_paths()\n",
    "for i in temp:\n",
    "    print(i)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_3000_4.edges', 'ba_edgelist_exp1_3000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_4000_4.edges', 'ba_edgelist_exp1_4000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_5000_4.edges', 'ba_edgelist_exp1_5000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_6000_4.edges', 'ba_edgelist_exp1_6000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_7000_4.edges', 'ba_edgelist_exp1_7000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_8000_4.edges', 'ba_edgelist_exp1_8000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_10.edges', 'ba_edgelist_exp2_2000_10')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_20.edges', 'ba_edgelist_exp2_2000_20')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_4.edges', 'ba_edgelist_exp2_2000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_10.edges', 'ba_edgelist_exp3_4000_10')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_2.edges', 'ba_edgelist_exp3_4000_2')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_6.edges', 'ba_edgelist_exp3_4000_6')\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "rmv= ['ba_edgelist_1000_10', \"ba_edgelist_1000_20\", \"ba_edgelist_1000_4\", \"ba_edgelist_2000_10\", \"ba_edgelist_2000_20\", \"ba_edgelist_2000_4\", \"ba_edgelist_3000_10\", \"ba_edgelist_3000_20\", \"ba_edgelist_3000_4\"]\n",
    "temp = [x for x in temp if x[1] not in rmv]\n",
    "for i in temp:\n",
    "    print(i)\n",
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./datasets/BA_EXP\\\\ba_edgelist_exp1_3000_4.edges', 'ba_edgelist_exp1_3000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_4000_4.edges', 'ba_edgelist_exp1_4000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_5000_4.edges', 'ba_edgelist_exp1_5000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_6000_4.edges', 'ba_edgelist_exp1_6000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_7000_4.edges', 'ba_edgelist_exp1_7000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_8000_4.edges', 'ba_edgelist_exp1_8000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_10.edges', 'ba_edgelist_exp2_2000_10'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_20.edges', 'ba_edgelist_exp2_2000_20'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_4.edges', 'ba_edgelist_exp2_2000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_10.edges', 'ba_edgelist_exp3_4000_10'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_2.edges', 'ba_edgelist_exp3_4000_2'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_6.edges', 'ba_edgelist_exp3_4000_6')]\n",
      "[('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_4.edges', 'ba_edgelist_exp2_2000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_10.edges', 'ba_edgelist_exp2_2000_10'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_20.edges', 'ba_edgelist_exp2_2000_20'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_3000_4.edges', 'ba_edgelist_exp1_3000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_2.edges', 'ba_edgelist_exp3_4000_2'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_4000_4.edges', 'ba_edgelist_exp1_4000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_6.edges', 'ba_edgelist_exp3_4000_6'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_10.edges', 'ba_edgelist_exp3_4000_10'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_5000_4.edges', 'ba_edgelist_exp1_5000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_6000_4.edges', 'ba_edgelist_exp1_6000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_7000_4.edges', 'ba_edgelist_exp1_7000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_8000_4.edges', 'ba_edgelist_exp1_8000_4')]\n",
      "4\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(temp)\n",
    "list.sort(temp, key=getSortValue)\n",
    "print(temp)\n",
    "ba_mch_0 = getSubList(temp, 0, 3)\n",
    "ba_mch_1 = getSubList(temp, 1, 3)\n",
    "ba_mch_2 = getSubList(temp, 2, 3)\n",
    "print(len(ba_mch_0))\n",
    "print(len(ba_mch_1))\n",
    "print(len(ba_mch_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ba_mch_0:\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_4.edges', 'ba_edgelist_exp2_2000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_3000_4.edges', 'ba_edgelist_exp1_3000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_6.edges', 'ba_edgelist_exp3_4000_6')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_6000_4.edges', 'ba_edgelist_exp1_6000_4')\n",
      "ba_mch_1:\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_10.edges', 'ba_edgelist_exp2_2000_10')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_2.edges', 'ba_edgelist_exp3_4000_2')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_10.edges', 'ba_edgelist_exp3_4000_10')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_7000_4.edges', 'ba_edgelist_exp1_7000_4')\n",
      "ba_mch_2:\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_20.edges', 'ba_edgelist_exp2_2000_20')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_4000_4.edges', 'ba_edgelist_exp1_4000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_5000_4.edges', 'ba_edgelist_exp1_5000_4')\n",
      "('./datasets/BA_EXP\\\\ba_edgelist_exp1_8000_4.edges', 'ba_edgelist_exp1_8000_4')\n"
     ]
    }
   ],
   "source": [
    "print('ba_mch_0:')\n",
    "for i in ba_mch_0:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "print('ba_mch_1:')\n",
    "for i in ba_mch_1:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "print('ba_mch_2:')\n",
    "for i in ba_mch_2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "di = {}\n",
    "di['BA_mch_0'] = [item[1] for item in ba_mch_0]\n",
    "# di['BA_mch_0'].append('ChicagoRegional')\n",
    "# di['BA_mch_0'].append('ia-crime-moreno')\n",
    "di['BA_mch_0'].append('p2p-Gnutella04')\n",
    "# di['BA_mch_0'].append('jazz')\n",
    "di['BA_mch_0'].append('LastFM')\n",
    "\n",
    "\n",
    "di['BA_mch_1'] = [item[1] for item in ba_mch_1]\n",
    "# di['BA_mch_1'].append('sex')\n",
    "di['BA_mch_1'].append('powergrid')\n",
    "di['BA_mch_1'].append('vidal')\n",
    "di['BA_mch_1'].append('politician_edges')\n",
    "\n",
    "\n",
    "\n",
    "di['BA_mch_2'] = [item[1] for item in ba_mch_2]\n",
    "# di['BA_mch_2'].append('maybe-PROTEINS-full')\n",
    "# di['BA_mch_2'].append('arenas-pgp')\n",
    "\n",
    "# di['negin_mch'] = ['CA-GrQc', 'CA-HepTh', 'faa', 'facebook_combined', 'figeys', 'email', 'NS', 'Peh_edge', 'Stelzl', 'tvshow_edges', 'web-EPA']\n",
    "di['negin_mch'] = ['CA-GrQc', 'CA-HepTh', 'facebook_combined', 'figeys', 'email', 'Peh_edge', 'Stelzl', 'tvshow_edges', 'web-EPA', 'arenas-pgp']\n",
    "di['mhd_mch'] = [ 'ChicagoRegional', 'ia-crime-moreno', 'maybe-PROTEINS-full', 'NS', 'faa',                  'jazz', 'sex']   #TODO: THESE TWO LAST ONES SHOULD BE DONE LATERd\n",
    "\n",
    "write_to_mch_json = False\n",
    "if write_to_mch_json:\n",
    "    with open('machine.json', 'w') as f:\n",
    "        json.dump(di, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BA_mch_0': ['ba_edgelist_exp1_3000_4', 'ba_edgelist_exp3_4000_6', 'ba_edgelist_exp1_6000_4', 'p2p-Gnutella04', 'LastFM'], 'BA_mch_1': ['ba_edgelist_exp2_2000_10', 'ba_edgelist_exp3_4000_2', 'ba_edgelist_exp3_4000_10', 'ba_edgelist_exp1_7000_4', 'vidal', 'politician_edges'], 'BA_mch_2': ['ba_edgelist_exp2_2000_20', 'ba_edgelist_exp1_4000_4', 'ba_edgelist_exp1_5000_4', 'ba_edgelist_exp2_2000_4'], 'negin_mch': ['CA-GrQc', 'CA-HepTh', 'facebook_combined', 'figeys', 'email', 'Peh_edge', 'Stelzl', 'tvshow_edges', 'web-EPA', 'arenas-pgp', 'powergrid', 'ba_edgelist_exp1_8000_4'], 'mhd_mch': ['jazz', 'NS', 'faa', 'ba_edgelist_1000_4', 'ChicagoRegional', 'ia-crime-moreno', 'maybe-PROTEINS-full', 'sex']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('machine.json', 'r') as file:\n",
    "    di = json.load(file)\n",
    "\n",
    "print(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA_mch_0 : \n",
      "1 . ba_edgelist_exp1_3000_4   process: [3000, 3000, 3000] / 3000 completed:  True  sorted: True\n",
      "2 . ba_edgelist_exp3_4000_6   process: [4000, 4000, 4000] / 4000 completed:  True  sorted: True\n",
      "3 . ba_edgelist_exp1_6000_4   process: [6000, 6000, 6000] / 6000 completed:  True  sorted: True\n",
      "###  4 . p2p-Gnutella04   process: [2107, 2107, 2107] / 10876 completed:  False  sorted: False ### \n",
      "@@@@@@@@@@@@ has duplicate nodes in the node list, duplicates:  [np.int64(10504)]\n",
      "###  5 . LastFM   process: [7395, 7395, 7395] / 7624 completed:  False  sorted: False ### \n",
      "@@@@@@@@@@@@ has duplicate nodes in the node list, duplicates:  [np.int64(2263), np.int64(6793), np.int64(6794), np.int64(6795), np.int64(6796), np.int64(6797), np.int64(6798), np.int64(6799), np.int64(6800), np.int64(6801), np.int64(6802), np.int64(6803), np.int64(6804), np.int64(6805), np.int64(6806), np.int64(6807), np.int64(6808), np.int64(6809), np.int64(6810), np.int64(6811), np.int64(6812), np.int64(6813), np.int64(6814), np.int64(6815), np.int64(6816), np.int64(6817), np.int64(6818), np.int64(6819), np.int64(6820), np.int64(6821), np.int64(6822), np.int64(6823), np.int64(6824), np.int64(6825), np.int64(6826), np.int64(6827), np.int64(6828), np.int64(6829), np.int64(6830), np.int64(6831), np.int64(6832), np.int64(6833), np.int64(6834), np.int64(6835), np.int64(6836), np.int64(6837), np.int64(6838), np.int64(6839), np.int64(6840), np.int64(6841), np.int64(6842), np.int64(6843), np.int64(6844), np.int64(6845), np.int64(6846), np.int64(6847), np.int64(6848), np.int64(6849), np.int64(6850), np.int64(6851), np.int64(6852), np.int64(6853), np.int64(6854), np.int64(6855), np.int64(6856), np.int64(6857), np.int64(6858), np.int64(6859), np.int64(6860), np.int64(6861), np.int64(6862), np.int64(6863), np.int64(6864), np.int64(6865), np.int64(6866), np.int64(6867), np.int64(6868), np.int64(6869), np.int64(6870), np.int64(6871), np.int64(6872), np.int64(6873), np.int64(6874), np.int64(6875), np.int64(6876), np.int64(6877), np.int64(6878), np.int64(6879), np.int64(6880), np.int64(6881), np.int64(6882), np.int64(6883), np.int64(6884), np.int64(6885), np.int64(6886), np.int64(6887), np.int64(6888), np.int64(6889), np.int64(6890), np.int64(6891), np.int64(6892), np.int64(6893), np.int64(6894), np.int64(6895), np.int64(6896), np.int64(6897), np.int64(6898), np.int64(6899), np.int64(6900), np.int64(6901), np.int64(6902), np.int64(6903), np.int64(6904), np.int64(6905), np.int64(6906), np.int64(6907), np.int64(6908), np.int64(6909), np.int64(6910), np.int64(6911), np.int64(6912), np.int64(6913), np.int64(6914), np.int64(6915), np.int64(6916), np.int64(6917), np.int64(6918), np.int64(6919), np.int64(6920), np.int64(6921), np.int64(6922), np.int64(6923), np.int64(6924), np.int64(6925), np.int64(6926), np.int64(6927), np.int64(6928), np.int64(6929), np.int64(6930), np.int64(6931), np.int64(6932), np.int64(6933), np.int64(6934), np.int64(6935), np.int64(6936), np.int64(6937), np.int64(6938), np.int64(6939), np.int64(6940), np.int64(6941), np.int64(6942), np.int64(6943), np.int64(6944), np.int64(6945), np.int64(6946), np.int64(6947), np.int64(6948), np.int64(6949), np.int64(6950), np.int64(6951), np.int64(6952), np.int64(6953), np.int64(6954), np.int64(6955), np.int64(6956), np.int64(6957), np.int64(6958), np.int64(6959), np.int64(6960), np.int64(6961), np.int64(6962), np.int64(6963), np.int64(6964), np.int64(6965), np.int64(6966), np.int64(6967), np.int64(6968), np.int64(6969), np.int64(6970), np.int64(6971), np.int64(6972), np.int64(6973), np.int64(6974), np.int64(6975), np.int64(6976), np.int64(6977), np.int64(6978), np.int64(6979), np.int64(6980), np.int64(6981), np.int64(6982), np.int64(6983), np.int64(6984), np.int64(6985), np.int64(6986), np.int64(6987), np.int64(6988), np.int64(6989), np.int64(6990), np.int64(6991), np.int64(6992), np.int64(6993), np.int64(6994), np.int64(6995), np.int64(6996), np.int64(6997), np.int64(6998), np.int64(6999), np.int64(7000), np.int64(7001), np.int64(7002), np.int64(7003), np.int64(7004), np.int64(7005), np.int64(7006), np.int64(7007), np.int64(7008), np.int64(7009), np.int64(7010), np.int64(7011), np.int64(7012), np.int64(7013), np.int64(7014), np.int64(7015), np.int64(7016), np.int64(7017), np.int64(7018), np.int64(7019), np.int64(7020), np.int64(7021), np.int64(7022), np.int64(7023), np.int64(7024), np.int64(7025), np.int64(7026), np.int64(7027), np.int64(7028), np.int64(7029), np.int64(7030), np.int64(7031), np.int64(7032), np.int64(7033), np.int64(7034), np.int64(7035), np.int64(7036), np.int64(7037), np.int64(7038), np.int64(7039), np.int64(7040), np.int64(7041), np.int64(7042), np.int64(7043), np.int64(7044), np.int64(7045), np.int64(7046), np.int64(7047), np.int64(7048), np.int64(7049), np.int64(7050), np.int64(7051), np.int64(7052), np.int64(7053), np.int64(7054), np.int64(7055), np.int64(7056), np.int64(7057), np.int64(7058), np.int64(7059), np.int64(7060), np.int64(7061), np.int64(7062), np.int64(7063), np.int64(7064), np.int64(7065), np.int64(7066), np.int64(7067), np.int64(7068), np.int64(7069), np.int64(7070), np.int64(7071), np.int64(7072), np.int64(7073), np.int64(7074), np.int64(7075), np.int64(7076), np.int64(7077), np.int64(7078), np.int64(7079), np.int64(7080), np.int64(7081), np.int64(7082), np.int64(7083), np.int64(7084), np.int64(7085), np.int64(7086), np.int64(7087), np.int64(7088), np.int64(7089), np.int64(7090), np.int64(7091), np.int64(7092), np.int64(7093), np.int64(7094), np.int64(7095), np.int64(7096), np.int64(7097), np.int64(7098), np.int64(7099), np.int64(7100), np.int64(7101), np.int64(7102), np.int64(7103), np.int64(7104), np.int64(7105), np.int64(7106), np.int64(7107), np.int64(7108), np.int64(7109), np.int64(7110), np.int64(7111), np.int64(7112), np.int64(7113), np.int64(7114), np.int64(7115), np.int64(7116), np.int64(7117), np.int64(7118), np.int64(7119), np.int64(7120), np.int64(7121), np.int64(7122), np.int64(7123), np.int64(7124), np.int64(7125), np.int64(7126), np.int64(7127), np.int64(7128), np.int64(7129), np.int64(7130), np.int64(7131), np.int64(7132), np.int64(7133), np.int64(7134), np.int64(7135), np.int64(7136), np.int64(7137), np.int64(7138), np.int64(7139), np.int64(7140), np.int64(7141), np.int64(7142), np.int64(7143), np.int64(7144), np.int64(7145), np.int64(7146), np.int64(7147), np.int64(7148), np.int64(7149), np.int64(7150), np.int64(7151), np.int64(7152), np.int64(7153), np.int64(7154), np.int64(7155), np.int64(7156), np.int64(7157), np.int64(7158), np.int64(7159), np.int64(7160), np.int64(7161), np.int64(7162), np.int64(7163), np.int64(7164), np.int64(7165), np.int64(7166), np.int64(7167), np.int64(7168), np.int64(7169), np.int64(7170), np.int64(7171), np.int64(7172), np.int64(7173), np.int64(7174), np.int64(7175), np.int64(7176), np.int64(7177), np.int64(7178), np.int64(7179), np.int64(7180), np.int64(7181), np.int64(7182), np.int64(7183), np.int64(7184), np.int64(7185), np.int64(7186), np.int64(7187), np.int64(7188), np.int64(7189), np.int64(7190), np.int64(7191), np.int64(7192), np.int64(7193), np.int64(7194), np.int64(7195), np.int64(7196), np.int64(7197), np.int64(7198), np.int64(7199), np.int64(7200), np.int64(7201), np.int64(7202), np.int64(7203), np.int64(7204), np.int64(7205), np.int64(7206), np.int64(7207), np.int64(7208), np.int64(7209), np.int64(7210), np.int64(7211), np.int64(7212), np.int64(7213), np.int64(7214), np.int64(7215), np.int64(7216), np.int64(7217), np.int64(7218), np.int64(7219), np.int64(7220), np.int64(7221), np.int64(7222), np.int64(7223), np.int64(7224), np.int64(7225), np.int64(7226), np.int64(7227), np.int64(7228), np.int64(7229), np.int64(7230), np.int64(7231), np.int64(7232), np.int64(7233), np.int64(7234), np.int64(7235), np.int64(7236), np.int64(7237), np.int64(7238), np.int64(7239), np.int64(7240), np.int64(7241), np.int64(7242), np.int64(7243), np.int64(7244), np.int64(7245), np.int64(7246), np.int64(7247), np.int64(7248), np.int64(7249), np.int64(7250), np.int64(7251), np.int64(7252), np.int64(7253), np.int64(7254), np.int64(7255), np.int64(7256), np.int64(7257), np.int64(7258), np.int64(7259), np.int64(7260), np.int64(7261), np.int64(7262), np.int64(7263), np.int64(7264), np.int64(7265), np.int64(7266), np.int64(7267), np.int64(7268), np.int64(7269), np.int64(7270), np.int64(7271), np.int64(7272), np.int64(7273), np.int64(7274), np.int64(7275), np.int64(7276), np.int64(7277), np.int64(7278), np.int64(7279), np.int64(7280), np.int64(7281), np.int64(7282), np.int64(7283), np.int64(7284), np.int64(7285), np.int64(7286), np.int64(7287), np.int64(7288), np.int64(7289), np.int64(7290), np.int64(7291), np.int64(7292), np.int64(7293), np.int64(7294), np.int64(7295), np.int64(7296), np.int64(7297), np.int64(7298), np.int64(7299), np.int64(7300), np.int64(7301), np.int64(7302), np.int64(7303), np.int64(7304), np.int64(7305), np.int64(7306), np.int64(7307), np.int64(7308), np.int64(7309), np.int64(7310), np.int64(7311), np.int64(7312), np.int64(7313), np.int64(7314), np.int64(7315), np.int64(7316), np.int64(7317), np.int64(7318), np.int64(7319), np.int64(7320), np.int64(7321), np.int64(7322), np.int64(7323), np.int64(7324), np.int64(7325), np.int64(7326), np.int64(7327), np.int64(7328), np.int64(7329), np.int64(7330), np.int64(7331), np.int64(7332), np.int64(7333), np.int64(7334), np.int64(7335), np.int64(7336), np.int64(7337), np.int64(7338), np.int64(7339), np.int64(7340), np.int64(7341), np.int64(7342), np.int64(7343), np.int64(7344), np.int64(7345), np.int64(7346), np.int64(7347), np.int64(7348), np.int64(7349), np.int64(7350), np.int64(7351), np.int64(7352), np.int64(7353), np.int64(7354), np.int64(7355), np.int64(7356), np.int64(7357), np.int64(7358), np.int64(7359), np.int64(7360), np.int64(7361), np.int64(7362), np.int64(7363), np.int64(7364), np.int64(7365), np.int64(7366), np.int64(7367), np.int64(7368), np.int64(7369), np.int64(7370), np.int64(7371), np.int64(7372), np.int64(7373), np.int64(7374), np.int64(7375), np.int64(7376), np.int64(7377), np.int64(7378), np.int64(7379), np.int64(7380), np.int64(7381), np.int64(7382), np.int64(7383), np.int64(7384), np.int64(7385), np.int64(7386), np.int64(7387), np.int64(7388), np.int64(7389), np.int64(7390), np.int64(7391), np.int64(7392), np.int64(7393), np.int64(7394), np.int64(7395), np.int64(7396), np.int64(7397), np.int64(7398), np.int64(7399), np.int64(7400), np.int64(7401), np.int64(7402), np.int64(7403), np.int64(7404), np.int64(7405), np.int64(7406), np.int64(7407), np.int64(7408), np.int64(7409), np.int64(7410), np.int64(7411), np.int64(7412), np.int64(7413), np.int64(7414), np.int64(7415), np.int64(7416), np.int64(7417), np.int64(7418), np.int64(7419), np.int64(7420), np.int64(7421), np.int64(7422), np.int64(7423), np.int64(7424), np.int64(7425), np.int64(7426), np.int64(7427), np.int64(7428), np.int64(7429), np.int64(7430), np.int64(7431), np.int64(7432), np.int64(7433), np.int64(7434), np.int64(7435), np.int64(7436), np.int64(7437), np.int64(7438), np.int64(7439), np.int64(7440), np.int64(7441), np.int64(7442), np.int64(7443), np.int64(7444), np.int64(7445), np.int64(7446), np.int64(7447), np.int64(7448), np.int64(7449), np.int64(7450), np.int64(7451), np.int64(7452), np.int64(7453), np.int64(7454), np.int64(7455), np.int64(7456), np.int64(7457), np.int64(7458), np.int64(7459), np.int64(7460), np.int64(7461), np.int64(7462), np.int64(7463), np.int64(7464), np.int64(7465), np.int64(7466), np.int64(7467), np.int64(7468), np.int64(7469), np.int64(7470), np.int64(7471), np.int64(7472), np.int64(7473), np.int64(7474), np.int64(7475), np.int64(7476), np.int64(7477), np.int64(7478), np.int64(7479), np.int64(7480), np.int64(7481), np.int64(7482), np.int64(7483), np.int64(7484), np.int64(7485), np.int64(7486), np.int64(7487), np.int64(7488), np.int64(7489), np.int64(7490), np.int64(7491), np.int64(7492), np.int64(7493), np.int64(7494), np.int64(7495), np.int64(7496), np.int64(7497), np.int64(7498), np.int64(7499), np.int64(7500), np.int64(7501), np.int64(7502), np.int64(7503), np.int64(7504), np.int64(7505), np.int64(7506), np.int64(7507), np.int64(7508), np.int64(7509), np.int64(7510), np.int64(7511), np.int64(7512), np.int64(7513), np.int64(7514), np.int64(7515), np.int64(7516), np.int64(7517), np.int64(7518), np.int64(7519), np.int64(7520), np.int64(7521), np.int64(7522), np.int64(7523), np.int64(7524), np.int64(7525), np.int64(7526), np.int64(7527), np.int64(7528), np.int64(7529), np.int64(7530), np.int64(7531), np.int64(7532), np.int64(7533), np.int64(7534), np.int64(7535), np.int64(7536), np.int64(7537), np.int64(7538), np.int64(7539), np.int64(7540), np.int64(7541), np.int64(7542), np.int64(7543), np.int64(7544), np.int64(7545), np.int64(7546), np.int64(7547), np.int64(7548), np.int64(7549), np.int64(7550), np.int64(7551), np.int64(7552), np.int64(7553), np.int64(7554), np.int64(7555), np.int64(7556), np.int64(7557), np.int64(7558), np.int64(7559), np.int64(7560), np.int64(7561), np.int64(7562), np.int64(7563), np.int64(7564), np.int64(7565), np.int64(7566), np.int64(7567), np.int64(7568), np.int64(7569), np.int64(7570), np.int64(7571), np.int64(7572), np.int64(7573), np.int64(7574), np.int64(7575), np.int64(7576), np.int64(7577), np.int64(7578), np.int64(7579), np.int64(7580), np.int64(7581), np.int64(7582), np.int64(7583), np.int64(7584), np.int64(7585), np.int64(7586), np.int64(7587), np.int64(7588), np.int64(7589), np.int64(7590), np.int64(7591), np.int64(7592), np.int64(7593), np.int64(7594), np.int64(7595), np.int64(7596), np.int64(7597), np.int64(7598), np.int64(7599), np.int64(7600), np.int64(7601), np.int64(7602), np.int64(7603), np.int64(7604), np.int64(7605), np.int64(7606), np.int64(7607), np.int64(7608), np.int64(7609), np.int64(7610), np.int64(7611), np.int64(7612), np.int64(7613), np.int64(7614), np.int64(7615), np.int64(7616), np.int64(7617), np.int64(7618), np.int64(7619), np.int64(7620), np.int64(7621), np.int64(7622), np.int64(7623)]\n",
      "SIM NUM NODES / TOTAL NUM NODES:  22502  /  31500\n",
      "percentage:  71.43492063492064\n",
      "COMPLETED:  ['ba_edgelist_exp1_3000_4', 'ba_edgelist_exp3_4000_6', 'ba_edgelist_exp1_6000_4']\n",
      "INCOMPLETED:  ['p2p-Gnutella04', 'LastFM']\n",
      "-----------------\n",
      "BA_mch_1 : \n",
      "1 . ba_edgelist_exp2_2000_10   process: [2000, 2000, 2000] / 2000 completed:  True  sorted: True\n",
      "2 . ba_edgelist_exp3_4000_2   process: [4000, 4000, 4000] / 4000 completed:  True  sorted: True\n",
      "3 . ba_edgelist_exp3_4000_10   process: [4000, 4000, 4000] / 4000 completed:  True  sorted: True\n",
      "4 . ba_edgelist_exp1_7000_4   process: [7000, 7000, 7000] / 7000 completed:  True  sorted: True\n",
      "5 . vidal   process: [3133, 3133, 3133] / 3133 completed:  True  sorted: True\n",
      "6 . politician_edges   process: [5908, 5908, 5908] / 5908 completed:  True  sorted: True\n",
      "SIM NUM NODES / TOTAL NUM NODES:  26041  /  26041\n",
      "percentage:  100.0\n",
      "COMPLETED:  ['ba_edgelist_exp2_2000_10', 'ba_edgelist_exp3_4000_2', 'ba_edgelist_exp3_4000_10', 'ba_edgelist_exp1_7000_4', 'vidal', 'politician_edges']\n",
      "INCOMPLETED:  []\n",
      "-----------------\n",
      "BA_mch_2 : \n",
      "1 . ba_edgelist_exp2_2000_20   process: [2000, 2000, 2000] / 2000 completed:  True  sorted: True\n",
      "2 . ba_edgelist_exp1_4000_4   process: [4000, 4000, 4000] / 4000 completed:  True  sorted: True\n",
      "3 . ba_edgelist_exp1_5000_4   process: [5000, 5000, 5000] / 5000 completed:  True  sorted: True\n",
      "4 . ba_edgelist_exp2_2000_4   process: [2000, 2000, 2000] / 2000 completed:  True  sorted: True\n",
      "SIM NUM NODES / TOTAL NUM NODES:  13000  /  13000\n",
      "percentage:  100.0\n",
      "COMPLETED:  ['ba_edgelist_exp2_2000_20', 'ba_edgelist_exp1_4000_4', 'ba_edgelist_exp1_5000_4', 'ba_edgelist_exp2_2000_4']\n",
      "INCOMPLETED:  []\n",
      "-----------------\n",
      "negin_mch : \n",
      "1 . CA-GrQc   process: [5242, 5242, 5242] / 5242 completed:  True  sorted: True\n",
      "2 . CA-HepTh   process: [3886, 3886, 3886] / 9877 completed:  False  sorted: True\n",
      "3 . facebook_combined   process: [4039, 4039, 4039] / 4039 completed:  True  sorted: True\n",
      "4 . figeys   process: [2239, 2239, 2239] / 2239 completed:  True  sorted: True\n",
      "5 . email   process: [1133, 1133, 1133] / 1133 completed:  True  sorted: True\n",
      "6 . Peh_edge   process: [2426, 2426, 2426] / 2426 completed:  True  sorted: True\n",
      "7 . Stelzl   process: [1706, 1706, 1706] / 1706 completed:  True  sorted: True\n",
      "8 . tvshow_edges   process: [3892, 3892, 3892] / 3892 completed:  True  sorted: True\n",
      "9 . web-EPA   process: [4271, 4271, 4271] / 4271 completed:  True  sorted: True\n",
      "10 . arenas-pgp   process: [3821, 3821, 3821] / 10680 completed:  False  sorted: True\n",
      "11 . powergrid   process: [1308, 1308, 1308] / 4941 completed:  False  sorted: True\n",
      "12 . ba_edgelist_exp1_8000_4   process: [8000, 8000, 8000] / 8000 completed:  True  sorted: True\n",
      "SIM NUM NODES / TOTAL NUM NODES:  41963  /  58446\n",
      "percentage:  71.797898915238\n",
      "COMPLETED:  ['CA-GrQc', 'facebook_combined', 'figeys', 'email', 'Peh_edge', 'Stelzl', 'tvshow_edges', 'web-EPA', 'ba_edgelist_exp1_8000_4']\n",
      "INCOMPLETED:  ['CA-HepTh', 'arenas-pgp', 'powergrid']\n",
      "-----------------\n",
      "mhd_mch : \n",
      "1 . jazz   process: [198, 198, 198] / 198 completed:  True  sorted: True\n",
      "2 . NS   process: [864, 864, 864] / 1461 completed:  False  sorted: True\n",
      "3 . faa   process: [472, 472, 472] / 1226 completed:  False  sorted: True\n",
      "4 . ba_edgelist_1000_4   process: [1000, 1000, 1000] / 1000 completed:  True  sorted: True\n",
      "5 . ChicagoRegional   process: [0, 0, 0] / 12979 completed:  False  sorted: True\n",
      "6 . ia-crime-moreno   process: [0, 0, 0] / 829 completed:  False  sorted: True\n",
      "7 . maybe-PROTEINS-full   process: [0, 0, 0] / 43466 completed:  False  sorted: True\n",
      "8 . sex   process: [0, 0, 0] / 10106 completed:  False  sorted: True\n",
      "SIM NUM NODES / TOTAL NUM NODES:  2534  /  71265\n",
      "percentage:  3.5557426506700343\n",
      "COMPLETED:  ['jazz', 'ba_edgelist_1000_4']\n",
      "INCOMPLETED:  ['NS', 'faa', 'ChicagoRegional', 'ia-crime-moreno', 'maybe-PROTEINS-full', 'sex']\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "notsorted = [] \n",
    "noteq = []\n",
    "completed = []\n",
    "incomplete = []\n",
    "temp = False\n",
    "net_has_duplicate_name = []\n",
    "\n",
    "for mch in di.keys():\n",
    "    # if not mch=='BA_mch_1':\n",
    "    #     continue\n",
    "    print(mch, \": \")\n",
    "    i = 0\n",
    "\n",
    "    t_=0\n",
    "    s_=0\n",
    "    for net in di[mch]:\n",
    "        has_duplicates = get_has_duplicates(net)\n",
    "        temp = False\n",
    "        i+=1\n",
    "        simNodes = getSimNumNodes(net)\n",
    "        totalNumNodes = getTotalNumNodes(net)\n",
    "        t_+=totalNumNodes\n",
    "        s_+=simNodes[0]\n",
    "        sortd = sorted(get_previously_sim_values(get_sir_graph_paths(net)[0])) ==get_previously_sim_values(get_sir_graph_paths(net)[0])\n",
    "        if simNodes[0] >= totalNumNodes:\n",
    "            temp = True\n",
    "            completed.append(net)\n",
    "        else: \n",
    "            incomplete.append(net)\n",
    "        if not sortd :\n",
    "            # if mch == 'negin_mch':\n",
    "            notsorted.append(net)\n",
    "            print('### ', i, \".\", net, \"  process:\", simNodes, '/',  totalNumNodes, 'completed: ',temp,  ' sorted:', sortd, '### ')\n",
    "        elif not( simNodes[0]==simNodes[1] and simNodes[1]==simNodes[2]) :\n",
    "            noteq.append(net)\n",
    "            print('$$$ ', i, \".\", net, \"  process:\", simNodes, '/',  totalNumNodes, 'completed: ',temp,  ' sorted:', sortd, ('$$$ '))\n",
    "        else:\n",
    "            print( i, \".\", net, \"  process:\", simNodes, '/',  totalNumNodes, 'completed: ',temp,  ' sorted:', sortd)\n",
    "        if has_duplicates:\n",
    "            net_has_duplicate_name.append(net)\n",
    "            print(\"@@@@@@@@@@@@ has duplicate nodes in the node list, duplicates: \", get_duplicates(net))\n",
    "    print(\"SIM NUM NODES / TOTAL NUM NODES: \",s_, ' / ', t_)\n",
    "    try:\n",
    "        print(\"percentage: \",(s_/ t_)*100)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"percentage: ZeroDivisionError  :\",s_, '/', t_ )\n",
    "\n",
    "    print(\"COMPLETED: \", completed)\n",
    "    print(\"INCOMPLETED: \", incomplete)\n",
    "\n",
    "    completed=[]\n",
    "    incomplete = []\n",
    "    print(\"-----------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max value of column infected_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "max_infected_sum = float('-inf')  # Initialize to negative infinity\n",
    "for mch in di.keys():\n",
    "    # print(mch, \": \")\n",
    "    for net in di[mch]:\n",
    "        sir_paths = get_sir_graph_paths(net)\n",
    "        # print(sir_paths)\n",
    "        for file in sir_paths:\n",
    "            if file_exists(file):\n",
    "                df = pd.read_csv(file)\n",
    "                # print(df['Infected_sum'].max())\n",
    "                max_infected_sum = max(max_infected_sum, df['Infected_sum'].max())\n",
    "print(max_infected_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    for net in notsorted:\n",
    "        sir_paths = get_sir_graph_paths(net)\n",
    "        i = 0\n",
    "        for path in sir_paths:\n",
    "            i+=1\n",
    "            df = pd.read_csv(path)\n",
    "            df_sorted = df.sort_values(by='Node')\n",
    "            df_sorted.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p2p-Gnutella04\n",
      "LastFM\n"
     ]
    }
   ],
   "source": [
    "for net in notsorted:\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE full duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p2p-Gnutella04', 'LastFM']\n"
     ]
    }
   ],
   "source": [
    "print(net_has_duplicate_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net:  p2p-Gnutella04\n",
      " + File ./datasets/SIR_Results/p2p-Gnutella04\\0.csv updated, fully duplicated rows removed.\n",
      " + File ./datasets/SIR_Results/p2p-Gnutella04\\1.csv updated, fully duplicated rows removed.\n",
      " + File ./datasets/SIR_Results/p2p-Gnutella04\\2.csv updated, fully duplicated rows removed.\n",
      "net:  LastFM\n",
      " + File ./datasets/SIR_Results/LastFM\\0.csv updated, fully duplicated rows removed.\n",
      " + File ./datasets/SIR_Results/LastFM\\1.csv updated, fully duplicated rows removed.\n",
      " + File ./datasets/SIR_Results/LastFM\\2.csv updated, fully duplicated rows removed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def remove_full_duplicates(net_name):\n",
    "    sir_paths = get_sir_graph_paths(net_name)\n",
    "    for sir_graph_path in sir_paths:\n",
    "        try:\n",
    "            # Load the CSV file with explicit data types\n",
    "            df = pd.read_csv(sir_graph_path, dtype={'Node': int, 'SIR': float, 'Infected_sum': int})\n",
    "            \n",
    "            # Remove fully duplicated rows, ensuring all columns are considered\n",
    "            df_cleaned = df.drop_duplicates(subset=['Node', 'SIR', 'Infected_sum'])\n",
    "            \n",
    "            # Overwrite the original CSV file with the cleaned data\n",
    "            df_cleaned.to_csv(sir_graph_path, index=False)\n",
    "            original_count = len(df)\n",
    "            cleaned_count = len(df_cleaned)\n",
    "            if original_count > cleaned_count:\n",
    "                print(f\" + File {sir_graph_path} updated, fully duplicated rows removed.\")\n",
    "            else:\n",
    "                print(f\" - no FULLY duplicate rows in File {sir_graph_path}.\")\n",
    "\n",
    "        except OSError as e:\n",
    "            print(\"Error reading file:\", e)\n",
    "\n",
    "if False:\n",
    "    for net in net_has_duplicate_name:\n",
    "        print(\"net: \", net)\n",
    "        remove_full_duplicates(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net:  p2p-Gnutella04\n",
      "CSV file ./datasets/SIR_Results/p2p-Gnutella04\\0.csv updated: Averaged rows for nodes with duplicate entries.\n",
      "CSV file ./datasets/SIR_Results/p2p-Gnutella04\\1.csv updated: Averaged rows for nodes with duplicate entries.\n",
      "CSV file ./datasets/SIR_Results/p2p-Gnutella04\\2.csv updated: Averaged rows for nodes with duplicate entries.\n",
      "net:  LastFM\n",
      "CSV file ./datasets/SIR_Results/LastFM\\0.csv updated: Averaged rows for nodes with duplicate entries.\n",
      "CSV file ./datasets/SIR_Results/LastFM\\1.csv updated: Averaged rows for nodes with duplicate entries.\n",
      "CSV file ./datasets/SIR_Results/LastFM\\2.csv updated: Averaged rows for nodes with duplicate entries.\n"
     ]
    }
   ],
   "source": [
    "def average_node_values(net_name):\n",
    "    sir_paths = get_sir_graph_paths(net_name)\n",
    "    for sir_graph_path in sir_paths:\n",
    "        try:\n",
    "            # Load the CSV file\n",
    "            df = pd.read_csv(sir_graph_path)\n",
    "            \n",
    "            # Group by 'Node' and calculate the mean for the other columns\n",
    "            df_avg = df.groupby('Node', as_index=False).mean()\n",
    "            df_avg['Infected_sum'] = df_avg['Infected_sum'].astype(int)\n",
    "            df_avg['SIR'] = df_avg['SIR'].round(7)\n",
    "            \n",
    "            # Overwrite the original CSV file with the averaged data\n",
    "            df_avg.to_csv(sir_graph_path, index=False)\n",
    "            \n",
    "            print(f\"CSV file {sir_graph_path} updated: Averaged rows for nodes with duplicate entries.\")\n",
    "            \n",
    "        except OSError as e:\n",
    "            print(f\"Error reading file: {e}\")\n",
    "            \n",
    "if False:\n",
    "    for net in net_has_duplicate_name:\n",
    "        print(\"net: \", net)\n",
    "        average_node_values(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_sir_precision_and_plot(csv_file_path, name):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    data = None\n",
    "    if file_exists(csv_file_path):\n",
    "        data = pd.read_csv(csv_file_path)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    # Check if the 'SIR' column exists\n",
    "    if 'SIR' not in data.columns:\n",
    "        raise ValueError(\"The 'SIR' column does not exist in the provided CSV file.\")\n",
    "\n",
    "    # Extract the SIR values\n",
    "    sir_values = data['SIR']\n",
    "    \n",
    "    # Check the precision of each value (5 or 3 decimal places)\n",
    "    rounded_to_5 = sir_values.apply(lambda x: len(str(x).split(\".\")[1]) == 5 if \".\" in str(x) else False).sum()\n",
    "    rounded_to_3 = sir_values.apply(lambda x: len(str(x).split(\".\")[1]) == 3 if \".\" in str(x) else False).sum()\n",
    "    \n",
    "    \n",
    "    # if rounded_to_3 == 0 or (rounded_to_3 > 0 and rounded_to_5 > 0) :\n",
    "    if name=='maybe-PROTEINS-full' or name== 'ChicagoRegional':\n",
    "        return  0\n",
    "    \n",
    "    print(name)\n",
    "    # Print the results\n",
    "    print(f\"Values rounded to 5 digits after the point: {rounded_to_5}\")\n",
    "    print(f\"Values rounded to 3 digits after the point: {rounded_to_3}\")\n",
    "\n",
    "    # Plot the histogram of the SIR values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(sir_values, bins=30, edgecolor='black', alpha=0.7)\n",
    "    plt.title(f\"Histogram of SIR Values {name}\")\n",
    "    plt.xlabel(\"SIR Values\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    # plt.show()\n",
    "    # plt.savefig(f\"./sir_labeling/images/prec_3/hist_sir_prec3_{name}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"./sir_labeling/images/prec_5/hist_sir_prec5_{name}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return rounded_to_3\n",
    "\n",
    "# Example usage\n",
    "# check_sir_precision_and_plot(\"path_to_your_csv_file.csv\")\n",
    "if False:\n",
    "\n",
    "    sum_redo_nodes = 0\n",
    "    for mch in di.keys():\n",
    "        print(mch, \": \")\n",
    "        mch_sum=0\n",
    "        for net in di[mch]:\n",
    "            sir_paths = get_sir_graph_paths(net)\n",
    "            redo_nodes= check_sir_precision_and_plot(sir_paths[0], net)\n",
    "            sum_redo_nodes+=redo_nodes\n",
    "            mch_sum+=redo_nodes\n",
    "        print(f\"this machine {mch} has to do {mch_sum}\")\n",
    "    print(sum_redo_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sir_with_3_digit_precision(csv_file_path, output_file_path):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Check if the 'SIR' column exists\n",
    "    if 'SIR' not in data.columns:\n",
    "        raise ValueError(\"The 'SIR' column does not exist in the provided CSV file.\")\n",
    "\n",
    "    # Remove rows where 'SIR' values have 3 decimal places\n",
    "    filtered_data = data[~data['SIR'].apply(lambda x: len(str(x).split(\".\")[1]) == 3 if \".\" in str(x) else False)]\n",
    "\n",
    "    # Save the filtered DataFrame to a new CSV file\n",
    "    filtered_data.to_csv(output_file_path, index=False)\n",
    "    print(f\"Filtered data saved to {output_file_path}\")\n",
    "\n",
    "\n",
    "if False:\n",
    "\n",
    "    for mch in di.keys():\n",
    "        for net in di[mch]:\n",
    "            sir_paths = get_sir_graph_paths(net)\n",
    "            if check_sir_precision_and_plot(sir_paths[0], net)>0:\n",
    "                remove_sir_with_3_digit_precision(sir_paths[0], sir_paths[0])\n",
    "                remove_sir_with_3_digit_precision(sir_paths[1], sir_paths[1])\n",
    "                remove_sir_with_3_digit_precision(sir_paths[2], sir_paths[2])\n",
    "        print(f\"this machine {mch} has to do {mch_sum}\")\n",
    "    print(sum_redo_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIR Result Convergence point of the different graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
