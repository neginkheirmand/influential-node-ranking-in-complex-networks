{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ba_graph_paths(dataset_dir= \"./datasets/\"):\n",
    "    graph_list = []\n",
    "    for dirpath, _, files in os.walk(dataset_dir):\n",
    "        for filename in files:\n",
    "            try:\n",
    "                if filename.startswith(\"ba_edgelist\") and filename.endswith(\".edges\"):\n",
    "                    file_path = os.path.join(dirpath, filename) \n",
    "                    graph_list.append((file_path, os.path.splitext(filename)[0]))\n",
    "            except Exception as e: \n",
    "                print(e, f'{filename}')\n",
    "    return graph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_graph_paths(dataset_dir= \"./datasets/\"):\n",
    "    graph_list = []\n",
    "    for dirpath, _, files in os.walk(dataset_dir):\n",
    "        for filename in files:\n",
    "            try:\n",
    "                if filename.endswith(\".edges\"):\n",
    "                    file_path = os.path.join(dirpath, filename) \n",
    "                    graph_list.append((file_path, os.path.splitext(filename)[0]))\n",
    "            except Exception as e: \n",
    "                print(e, f'{filename}')\n",
    "    return graph_list\n",
    "\n",
    "\n",
    "def get_sir_graph_paths(net_name, num_b=3,  result_path = './datasets/SIR_Results/'):\n",
    "    paths= []\n",
    "    for i in range(num_b):\n",
    "        sir_dir =os.path.join(result_path, net_name)\n",
    "        sir_dir = os.path.join(sir_dir, f'{i}.csv')\n",
    "        paths.append(sir_dir)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def get_previously_sim_values(sir_graph_path):\n",
    "    try:\n",
    "        df = pd.read_csv(sir_graph_path)\n",
    "        values = df['Node'].tolist()\n",
    "        return values\n",
    "    except OSError as e:\n",
    "        return []\n",
    "\n",
    "def getTotalNumNodes(net_name):\n",
    "    graph_list = get_graph_paths()\n",
    "    path = ''\n",
    "    for tmp in graph_list:\n",
    "        if tmp[1]==net_name:\n",
    "            path = tmp[0]\n",
    "            \n",
    "    G = nx.read_edgelist(path, comments=\"%\", nodetype=int)\n",
    "    return G.number_of_nodes()\n",
    "\n",
    "\n",
    "def getSimNumNodes(net_name):\n",
    "    sir_paths = get_sir_graph_paths(net_name)\n",
    "    temp = [  len(get_previously_sim_values(path)) for path in sir_paths ]\n",
    "    return (temp)\n",
    "\n",
    "\n",
    "def getSortValue(net_edges_path):\n",
    "    net_edges_path=net_edges_path[0]\n",
    "    G = nx.read_edgelist(net_edges_path, comments=\"%\", nodetype=int)\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "    avg_degree = 2 * num_edges / num_nodes if num_nodes > 0 else 0\n",
    "    return num_nodes+avg_degree\n",
    "\n",
    "def getSubList(graphs, index, step):\n",
    "    sublits = []\n",
    "    for i in range(index, len(graphs), step):\n",
    "        sublits.append(graphs[i])\n",
    "    return sublits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./datasets/BA\\\\ba_edgelist_1000_10.edges', 'ba_edgelist_1000_10'), ('./datasets/BA\\\\ba_edgelist_1000_20.edges', 'ba_edgelist_1000_20'), ('./datasets/BA\\\\ba_edgelist_1000_4.edges', 'ba_edgelist_1000_4'), ('./datasets/BA\\\\ba_edgelist_2000_10.edges', 'ba_edgelist_2000_10'), ('./datasets/BA\\\\ba_edgelist_2000_20.edges', 'ba_edgelist_2000_20'), ('./datasets/BA\\\\ba_edgelist_2000_4.edges', 'ba_edgelist_2000_4'), ('./datasets/BA\\\\ba_edgelist_3000_10.edges', 'ba_edgelist_3000_10'), ('./datasets/BA\\\\ba_edgelist_3000_20.edges', 'ba_edgelist_3000_20'), ('./datasets/BA\\\\ba_edgelist_3000_4.edges', 'ba_edgelist_3000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_3000_4.edges', 'ba_edgelist_exp1_3000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_4000_4.edges', 'ba_edgelist_exp1_4000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_5000_4.edges', 'ba_edgelist_exp1_5000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_6000_4.edges', 'ba_edgelist_exp1_6000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_7000_4.edges', 'ba_edgelist_exp1_7000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_8000_4.edges', 'ba_edgelist_exp1_8000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_10.edges', 'ba_edgelist_exp2_2000_10'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_20.edges', 'ba_edgelist_exp2_2000_20'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_4.edges', 'ba_edgelist_exp2_2000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_10.edges', 'ba_edgelist_exp3_4000_10'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_2.edges', 'ba_edgelist_exp3_4000_2'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_6.edges', 'ba_edgelist_exp3_4000_6')]\n",
      "[('./datasets/BA\\\\ba_edgelist_1000_4.edges', 'ba_edgelist_1000_4'), ('./datasets/BA\\\\ba_edgelist_1000_10.edges', 'ba_edgelist_1000_10'), ('./datasets/BA\\\\ba_edgelist_1000_20.edges', 'ba_edgelist_1000_20'), ('./datasets/BA\\\\ba_edgelist_2000_4.edges', 'ba_edgelist_2000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_4.edges', 'ba_edgelist_exp2_2000_4'), ('./datasets/BA\\\\ba_edgelist_2000_10.edges', 'ba_edgelist_2000_10'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_10.edges', 'ba_edgelist_exp2_2000_10'), ('./datasets/BA\\\\ba_edgelist_2000_20.edges', 'ba_edgelist_2000_20'), ('./datasets/BA_EXP\\\\ba_edgelist_exp2_2000_20.edges', 'ba_edgelist_exp2_2000_20'), ('./datasets/BA\\\\ba_edgelist_3000_4.edges', 'ba_edgelist_3000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_3000_4.edges', 'ba_edgelist_exp1_3000_4'), ('./datasets/BA\\\\ba_edgelist_3000_10.edges', 'ba_edgelist_3000_10'), ('./datasets/BA\\\\ba_edgelist_3000_20.edges', 'ba_edgelist_3000_20'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_2.edges', 'ba_edgelist_exp3_4000_2'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_4000_4.edges', 'ba_edgelist_exp1_4000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_6.edges', 'ba_edgelist_exp3_4000_6'), ('./datasets/BA_EXP\\\\ba_edgelist_exp3_4000_10.edges', 'ba_edgelist_exp3_4000_10'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_5000_4.edges', 'ba_edgelist_exp1_5000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_6000_4.edges', 'ba_edgelist_exp1_6000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_7000_4.edges', 'ba_edgelist_exp1_7000_4'), ('./datasets/BA_EXP\\\\ba_edgelist_exp1_8000_4.edges', 'ba_edgelist_exp1_8000_4')]\n",
      "7\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "temp = get_ba_graph_paths()\n",
    "print(temp)\n",
    "list.sort(temp, key=getSortValue)\n",
    "print(temp)\n",
    "ba_mch_0 = getSubList(temp, 0, 3)\n",
    "ba_mch_1 = getSubList(temp, 1, 3)\n",
    "ba_mch_2 = getSubList(temp, 2, 3)\n",
    "print(len(ba_mch_0))\n",
    "print(len(ba_mch_1))\n",
    "print(len(ba_mch_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "di = {}\n",
    "di['BA_mch_0'] = [item[1] for item in ba_mch_0]\n",
    "di['BA_mch_1'] = [item[1] for item in ba_mch_1]\n",
    "di['BA_mch_2'] = [item[1] for item in ba_mch_2]\n",
    "di['negin_mch'] = ['CA-GrQc', 'CA-HepTh', 'faa', 'facebook_combined', 'figeys', 'email', 'NS', 'Peh_edge', 'Stelzl', 'tvshow_edges', 'vidal', 'web-EPA']\n",
    "di['mhd_mch'] = ['ChicagoRegional', 'jazz', 'ia-crime-moreno', 'arenas-pgp', 'LastFM', 'maybe-PROTEINS-full', 'p2p-Gnutella04', 'sex']\n",
    "with open('machine.json', 'w') as f:\n",
    "    json.dump(di, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA_mch_0 : \n",
      "1 ) ba_edgelist_1000_4   process: [0, 0, 0] / 1000  sorted: True\n",
      "2 ) ba_edgelist_2000_4   process: [0, 0, 0] / 2000  sorted: True\n",
      "3 ) ba_edgelist_exp2_2000_10   process: [0, 0, 0] / 2000  sorted: True\n",
      "4 ) ba_edgelist_3000_4   process: [0, 0, 0] / 3000  sorted: True\n",
      "5 ) ba_edgelist_3000_20   process: [0, 0, 0] / 3000  sorted: True\n",
      "6 ) ba_edgelist_exp3_4000_6   process: [0, 0, 0] / 4000  sorted: True\n",
      "7 ) ba_edgelist_exp1_6000_4   process: [0, 0, 0] / 6000  sorted: True\n",
      "TOTAL NUM NODES:  21000\n",
      "-----------------\n",
      "BA_mch_1 : \n",
      "1 ) ba_edgelist_1000_10   process: [488, 488, 488] / 1000  sorted: True\n",
      "2 ) ba_edgelist_exp2_2000_4   process: [0, 0, 0] / 2000  sorted: True\n",
      "3 ) ba_edgelist_2000_20   process: [0, 0, 0] / 2000  sorted: True\n",
      "4 ) ba_edgelist_exp1_3000_4   process: [0, 0, 0] / 3000  sorted: True\n",
      "5 ) ba_edgelist_exp3_4000_2   process: [0, 0, 0] / 4000  sorted: True\n",
      "6 ) ba_edgelist_exp3_4000_10   process: [0, 0, 0] / 4000  sorted: True\n",
      "7 ) ba_edgelist_exp1_7000_4   process: [0, 0, 0] / 7000  sorted: True\n",
      "TOTAL NUM NODES:  23000\n",
      "-----------------\n",
      "BA_mch_2 : \n",
      "1 ) ba_edgelist_1000_20   process: [0, 0, 0] / 1000  sorted: True\n",
      "2 ) ba_edgelist_2000_10   process: [0, 0, 0] / 2000  sorted: True\n",
      "3 ) ba_edgelist_exp2_2000_20   process: [0, 0, 0] / 2000  sorted: True\n",
      "4 ) ba_edgelist_3000_10   process: [161, 161, 161] / 3000  sorted: True\n",
      "5 ) ba_edgelist_exp1_4000_4   process: [0, 0, 0] / 4000  sorted: True\n",
      "6 ) ba_edgelist_exp1_5000_4   process: [0, 0, 0] / 5000  sorted: True\n",
      "7 ) ba_edgelist_exp1_8000_4   process: [0, 0, 0] / 8000  sorted: True\n",
      "TOTAL NUM NODES:  25000\n",
      "-----------------\n",
      "negin_mch : \n",
      "1 ) CA-GrQc   process: [560, 560, 560] / 5242  sorted: True\n",
      "2 ) CA-HepTh   process: [180, 180, 180] / 9877  sorted: True\n",
      "3 ) faa   process: [1226, 1226, 1226] / 1226  sorted: True\n",
      "4 ) facebook_combined   process: [820, 820, 820] / 4039  sorted: True\n",
      "5 ) figeys   process: [791, 791, 791] / 2239  sorted: True\n",
      "6 ) email   process: [1133, 1133, 1133] / 1133  sorted: True\n",
      "7 ) NS   process: [1236, 1236, 1236] / 1461  sorted: True\n",
      "8 ) Peh_edge   process: [183, 183, 183] / 2426  sorted: True\n",
      "9 ) Stelzl   process: [0, 0, 0] / 1706  sorted: True\n",
      "10 ) tvshow_edges   process: [0, 0, 0] / 3892  sorted: True\n",
      "11 ) vidal   process: [0, 0, 0] / 3133  sorted: True\n",
      "12 ) web-EPA   process: [0, 0, 0] / 4271  sorted: True\n",
      "TOTAL NUM NODES:  40645\n",
      "-----------------\n",
      "mhd_mch : \n",
      "1 ) ChicagoRegional   process: [449, 449, 449] / 12979  sorted: True\n",
      "2 ) jazz   process: [198, 198, 198] / 198  sorted: True\n",
      "3 ) ia-crime-moreno   process: [829, 829, 829] / 829  sorted: True\n",
      "4 ) arenas-pgp   process: [544, 544, 544] / 10680  sorted: True\n",
      "5 ) LastFM   process: [320, 320, 320] / 7624  sorted: True\n",
      "6 ) maybe-PROTEINS-full   process: [55, 55, 55] / 43466  sorted: True\n",
      "7 ) p2p-Gnutella04   process: [144, 144, 144] / 10876  sorted: True\n",
      "8 ) sex   process: [0, 0, 0] / 10106  sorted: True\n",
      "TOTAL NUM NODES:  96758\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "notsorted = [] \n",
    "noteq = []\n",
    "for mch in di.keys():\n",
    "    print(mch, \": \")\n",
    "    i = 0\n",
    "\n",
    "    t_=0\n",
    "    for net in di[mch]:\n",
    "        i+=1\n",
    "        simNumNodes = getSimNumNodes(net)\n",
    "        totalNumNodes = getTotalNumNodes(net)\n",
    "        t_+=totalNumNodes\n",
    "        sortd = sorted(get_previously_sim_values(get_sir_graph_paths(net)[0])) ==get_previously_sim_values(get_sir_graph_paths(net)[0])\n",
    "        if not sortd :\n",
    "            notsorted.append(net)\n",
    "            print('### ', i, \")\", net, \"  process:\", simNumNodes, '/',  totalNumNodes, ' sorted:', sortd, '### ')\n",
    "        elif not( simNumNodes[0]==simNumNodes[1] and simNumNodes[1]==simNumNodes[2]) :\n",
    "            noteq.append(net)\n",
    "            print('$$$ ', i, \")\", net, \"  process:\", simNumNodes, '/',  totalNumNodes, ' sorted:', sortd, ('$$$ '))\n",
    "        else:\n",
    "            print( i, \")\", net, \"  process:\", simNumNodes, '/',  totalNumNodes, ' sorted:', sortd)\n",
    "    print(\"TOTAL NUM NODES: \", t_)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run:\n",
    "    for net in notsorted:\n",
    "        sir_paths = get_sir_graph_paths(net)\n",
    "        i = 0\n",
    "        for path in sir_paths:\n",
    "            i+=1\n",
    "            df = pd.read_csv(path)\n",
    "            df_sorted = df.sort_values(by='Node')\n",
    "            df_sorted.to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
